---
layout: default
title: Microservices auf Commodity Hardware Teil 3 - Continuous Delivery
shortTitle: Microservices und Commodity Hardware Teil 3
documentationExpanded: false
comments: true
postsExpanded: true
categories: microservices spring-boot distributed-systems
published: true
excerpt: excerpt
root: ../../
---

= Scaling out Microservices - Verteilte Systeme auf einfachster Hardware - Teil 3 - Provisionierung mit Ansible

== Ansible

Natürlich könnten wir jetzt Host für Host einzeln mit Telegraf bestücken um ordentliches Monitoring zu bekommen.
So viel Zeit haben wir aber nicht.

Diese Aufgaben manuell auszuführen ist mühsam, fehleranfällig und müssen jedesmal korrekt ausgeführt werden, wenn ein
 neuer Host mit in den Stack genommen wird - auch wenn das am Samstag abend aufgrund einer Lastspitze geschieht.
Idealerweise automatisieren wir diesen Prozess so weit als möglich undzwar mit einem möglichst geeigneten Tool - die
erste Wahl hierfür ist https://www.ansible.com[Ansible].
Ansible arbeitet schnell, einfach, effizient - und hat nur minimale Anforderungen and die zu provisionierenden Hosts.

=== Hosts provisionieren

Ansible benötigt neben sich selbst nicht viel mehr als Python vorprovisioniert - und Python kommt mit den meisten
Distributionen automatisch - _leider nicht mit unserer_. Prüfen wir kurz ob das korrekt ist.

[source, bash]
----
ssh pirate@pi25 python
pirate@pi25's password:
bash: python: command not found
----

Als einen der letzten letzten manuellen Schritt installieren wir Python auf allen Hosts.
Dazu loggen wir uns ein und führen diesen Befehl aus.

[source, bash]
----
 sudo apt-get install -y python && sudo apt-get install -y ansible
----

Würden wir neue Server bestellen wären diese Tools neben einem installierten Docker-Daemon ein Requirement.
Es macht einen massiven Unterschied, ob wir Server mit grundsätzlichen Tools (nicht-funktional!) von der zusändigen
Abteilung bestücken lassen, oder ob diese auch dafür zuständig sind, beispielsweise neue Tools und Libraries wie
Telegraf auf den einzelnen Servern zu installieren.
Telegraf ist applikationsspezifisch - sollten wir uns irgendwann entscheiden, statt _Telegraf_ etwas wie _collectd_
zu verwenden, was funktional fast identisch ist, dann ist das eine rein funktionale Entscheidung  auf
Applikationsebene und hat nichts mit dem Betrieb zu tun.

Zuletzt werden wir auf jedem Host den login per SSH-Key ermöglichen. Ansible selbst unterstützt auch SSH-Login per
User / Password, viel einfacher und weniger Fehleranfällig ist aber der Login per SSH-Key.

TIP: Dieses Tutorial geht davon aus, dass Sie grundlegend vertraut sind im Umgang mit SSH.
Falls nicht empfiehlt sich das Tutorial unter TODO.

[source, bash]
----
ssh-copy-id -i ~/.ssh/id_rsa.pub pirate@192.168.178.28 <1>
----
<1> Kopieren des SSH Key auf jeden einzelnen Host.

=== Ansible Inventory

Als ersten Schritt definieren wir das _Ansible-Inventory_-File im Ordner _assets/ansible_. Das Inventory-File
beschreibt, welche Hosts aktuell im System vorhanden und in welche Gruppen diese unterteilt sind. Das Inventory-File hat ein sehr einfaches
Format, für meinen Cluster sieht das File beispielsweise so aus.

TIP: Mehr Infos über das Inventory Format finden Sie in der hervorragenden http://docs.ansible
.com/ansible/intro_inventory.html[Online-Dokumentation] von Ansible.

[source,bash]
----
[nodes]
192.168.178.23
192.168.178.24
192.168.178.25
192.168.178.28
192.168.178.48
----

Hiermit definieren wir die Gruppe _nodes_ und weisen dieser Gruppe die Hosts mit den jeweiligen IPs zu.
Ein erster Test mit ansible besteht darin, die Hosts anzupingen.

[source,bash]
----
ansible all -i hosts -m ping -u pirate
----

Mit _all_ definieren wir, dass alle Hosts aus dem Inventory-File angepinged werden sollen.
Mit "-u" definieren wir den SSH User. Mit "-i" legen wir festm welches Inventory-File geladen wird.
Der "-m" Parameter legt fest, was Ansible ausführen soll.

Ist der Ping erfolgreich sieht die Antwort in etwa so aus.

[source, bash]
----
192.168.178.48 | success >> {
    "changed": false,
    "ping": "pong"
}
----

Fehlt auf dem Host beispielsweise Python schlägt der Ping fehl mit einer Fehlermeldung dieser Art.

[source, bash]
----
192.168.178.28 | FAILED >> {
    "failed": true,
    "msg": "/bin/sh: 1: /usr/bin/python: not found\r\nOpenSSH_6.9p1, LibreSSL 2.1.8\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 21: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug1: mux_client_request_session: master session id: 2\r\nShared connection to 192.168.178.28 closed.\r\n",
    "parsed": false
}
----

Funktioniert der Ping bei allen Hosts ist endlich Ansible bereit und korrekt konfiguriert.

=== Rollen und Playbooks

Ansible abstrahiert von der Idee Maschinen zu provisionieren und fokussiert sich darauf, den Stack zu modellieren.
In Ansible definieren wir nicht, dass auf dem Host _Pi25_ ein Tool wie Telegraf installiert werden soll, sondern wir
sagen, die Maschine _Pi25_ ist ein Cluster-Node, und Cluster-Nodes werden mit Telegraf provisioniert. Wir
modellieren quasi unseren Stack.

Zunächst legen wir die von Ansible erwartete Dateistruktur an.

image::/assets/images/03_file_hierarchy.jpeg[Ansible Dateistruktur, 800]

Rollendefinitionen, wie beispielsweise was für die Rolle _metered-node_ erfüllt sein muss erwartet Ansible im Ordner
_roles_. Ansible basiert sehr stark auf Konvention, daher halten wir uns an die von Ansible gemachten Vorschläge für
die Dateiorganisation, weil dann die meisten Dateien _einfach_ gefunden werden.

Im Ordner _roles_ legen wir folgende Unterordner an.

- tasks - Im Order _tasks_ werden die Aufgaben definiert, die Ansible für die Rolle _metered-node_ erfüllen muss.
- vars - Im Order _vars_ können wir Variablen definieren, die für das Playbook verwendet werden. Dies können
beispielsweise URLs sein, Usernamen, Ordner etc.
- files - Im Ordner _files_ werden Dateien abgelegt, die Ansible in den Tasks benötigt, beispielsweise die
Telegraf-Konfiguration die auf die jeden der Hosts kopiert werden soll.
- handlers - Im Order _handlers_ legen wir sogenannte _Handler-Definitionen_ fest. Man kann das als kleine Event-Handler
betrachten, die auf bestimmte Ereignisse im Ablauf eines Playbooks reagieren.

Zunächst kümmern wir uns um die Definition unseres _Playbooks_. Ein Ansible-Playbook kann ein bisschen wie ein
Skript während eines Filmdrehs betrachtet werden. Dort steht präzise, welche Schritte in welcher Reihenfolge
abgearbeitet werden müssen um das gewünschte Ergebnis zu erzielen.

Ein Playbook wird in standard-*yaml* Format beschrieben. Zunächst starten wir einen neuen Abschnitt mit ----.

Danach wird festgelegt, für welche Gruppen von Nodes das Playbook gelten soll.

[source, bash]
----
---
- hosts: nodes <1>
- roles:
  - metered-node <2>
----
<1> Die Gruppendefinition aus der _hosts_-Datei.
<2> Liste an Rollendefinitionen für diesen _Play_. Ansible erwartet einen Unterordner mit diesem Namen im Ordner
_roles_.

In jedem der Unterordner sucht Ansible automatisch nach einer Datei _main.yml_.
Zunächst legen wir die einzelnen Aufgaben (tasks) fest, indem wir die Datei _main.yml_ im Ordner _tasks_ anlegen.

{%raw%}
[source, bash]
----
---
#file tasks/main.yml
- name: get telegraf <1>
  get_url: url={{telegraf_uri}} dest=/tmp/telegraf_{{telegraf_version}}.deb  mode=0740 timeout=250 <2>
- name: install telegraf
  apt: deb=/tmp/telegraf_{{telegraf_version}}.deb <3>
- name: cleanup
  command: rm /tmp/telegraf_{{telegraf_version}}.deb
- name: Assures /etc/telegraf dir exists
  file: path=/etc/telegraf state=directory
- name: Provision Telegraf Config
  copy: src=telegraf.conf dest=/etc/telegraf/telegraf.conf owner=pirate mode="u=r,g=r,o=r" <4>
  notify: <5>
      - reload systemd <6>
----
{%endraw%}

<1> Jeder Task hat einen Menschenlesbaren Namen
<2> Jeder Task hat eine Aufgabendefinition, hier beispielsweise mit dem Modul _get_url_, quasi das Ansible-Wget laden
 wir das Telegraf-Binary herunter und speichern es einfach in /tmp.
<3> Wir installieren das Binary.
<4> Wir kopieren die Datei _telegraf.conf_ von unserem Rechner auf alle Host-Rechner in das Verzeichnis _/etc/telegraf_.
<5> Unter Notify können Handler notifiziert werden.
<6> Wir Notifizieren den Handler mit dem Namen _reload systemd_. Der Handler ist bisher nicht definiert.

Die Tasks selbst bauen aufeinander auf und sind eigentlich selbsterklärend und sprechend.
In der Task-Definition haben wir Variablen-Definitionen. Expressions in Ansible werden mit
{%raw%}{{variable}}{%endraw%} deklariert. Variablendefinitionen kommen aus der _main.yml_ im _vars_ Ordner.

Wir arbeiten mit den Variablen _telegraf_version_ und _telegraf_uri_.
Damit bei der Ausführen des Playbooks die Platzhalter korrekt ersetzt werden können definieren wir jetzt die _main
.yml_ im _vars_-Ordner.

[source, bash]
----
#file vars/main.yml
telegraf_version: 1.0.0-beta1_armhf
telegraf_uri: https://dl.influxdata.com/telegraf/releases/telegraf_{{telegraf_version}}.deb
----

Damit wird die Expression {%raw%}{{telegraf_version}}{%endraw%} durch die Definition _1.0.0-beta-1_armhf_ ersetzt.

Im Task 5 wird die Telegraf-Konfiguration auf jeden Host in der Nodes-Gruppe kopiert. Die Telegraf-Konfiguration
holen wir uns zuvor über SCP von einem der bereits konfigurierten Knoten.

TIP: Idealerweise besorgen sie sich die Konfiguration des Knotens der sich über die IP und nicht über _localhost_ auf
 die InfluxDB verbindet. Diese Konfiguration ist direkt wiederverwendbar.

[source, bash]
----
scp pirate@pi24:/etc/telegraf/telegraf.conf roles/files/telegraf.conf
----

Die Konfiguaration legen wir im Ordner _files_ ab. Diese Dateien sind in Tasks direkt verwendbar.
Das Copy-Modul im Task _Provision Telegraf Config_ erwartet das _src_-Attribut. Dateien die hier angegeben werden
werden direkt im _files_-Ordner gesucht und gefunden.

Zuletzt müssen wir noch dafür sorgen, dass die SystemD-Konfiguration für Telegraf neu geladen wird, sobald wir die
neue Konfiguration auf alle Hosts kopiert haben.
Hierfür definieren wir einen Handler in _handlers/main.yml_.

[source, bash]
----
#file handlers/main.yml
- name: reload systemd
  sudo: yes
  command: systemctl restart telegraf
----

Warum definieren wir das Reload der SystemD-Konfiguration über einen Handler und nicht einfach als weiteren Task?
_Handlers_ werden nur getriggert, wenn ein Task _changes_ meldet. Wird ein Task ausgeführt, aber nichts hat sich
verändet, weil beispielsweise die Konfiguration schon da ist wird der Handler nicht getriggert und SystemD nicht neu
gestartet, währenddessen ein weiterer Task unabhängig davon ausgeführt wird.

Damit ist alles vorbereitet und wir können versuchen, das Playbook auszuführen.

CAUTION: Ansible versucht, so viel wie möglich parallel abzuarbeiten. Mein Heimnetzwerk verkraftet das nicht,
deswegen limitiere ich Ansible auf einen Knoten nach dem anderen.

[source, bash]
----
---
#file nodes.yml
- hosts: nodes
  # basically, run as sudo
  become: yes
  #only one node at a time
  serial: 1
  roles:
  - metered-node
----

Die Erwartung wäre, dass nach der Ausführung des Playbooks die neuen Nodes direkt in Grafana erscheinen.

[source, bash]
----
ansible-playbook -i hosts nodes.yml -u pirate
----

Und tatsächlich, direkt nachdem das Playbook ausgeführt ist erscheinen die einzelnen Knoten.

image::/assets/images/03_provisioned_metrics.png[Metriken, 800]

=== Docker

Eine Konfigurationänderung macht es jetzt nicht mehr notwendig, sich auf jeden einzelnen Knoten einzuloggen, sondern
wir editieren das Konfigurationsfile (erhalten damit automatisch eine Versionierung der Datei) und lassen
anschließend einfach das Playbook nochmal laufen.

Ist nur eine Konfigurationsänderung notwendig, kann man auch direkt bei diesem Task starten.

[source, bash]
----
ansible-playbook -i hosts nodes.yml -u pirate --start-at-task "Provision Telegraf Config"
----

Eine Konfigurationsänderung die ggf. Sinn machen könnte ist das Überwachen der laufenden Docker-Container in Influx /
 Grafana. Wie der Zufall will kann Telegraf über ein Input-Plugin Docker-Container überwachen und deren wichtigsten
 Metriken in die InfluxDB übertragen.
Eine reine Konfigurationsänderung, die wir schnell vornehmen können.

In der _telegraf.conf_ suchen wir den Abschnitt [[inputs.docker]] und entfernen die Kommentare. Dadurch aktivieren
wir das Plugin. Anschließend lassen wir das Playbook nochmals laufen und übertragen so die neue Konfiguration auf
alle Knoten.

[source, bash]
----
# # Read metrics about docker containers
[[inputs.docker]]
#   ## Docker Endpoint
#   ##   To use TCP, set endpoint = "tcp://[ip]:[port]"
#   ##   To use environment variables (ie, docker-machine), set endpoint = "ENV"
    endpoint = "unix:///var/run/docker.sock"
#   ## Only collect metrics for these containers, collect all if empty
#   container_names = []
#   ## Timeout for docker list, info, and stats commands
    timeout = "5s"
----

Nachdem das Playbook gestartet ist finden wir auf einem beliebigen Host in den Logs unter
_/var/logs/telegraf/telegraf.log_ folgende Fehlermeldung:

[source, bash]
----
2016/06/18 12:19:00 ERROR in input [docker]: Cannot connect to the Docker daemon. Is the docker daemon running on this host?
----

Das Problem ist, Telegraf läuft unter dem User _telegraf_. Dieser User ist aber nicht in der Docker-Gruppe und kann /
 darf folglich nicht auf den Socket unter _/var/run/docker.sock_ zugreifen.

Nichts einfacher als das. Hierfür definieren wir einen weiteren Task für das Playbook, der den Telegraf-User in die
Docker-Gruppe aufnimmt.

[source, bash]
----
- name: allow docker access to telegraf
  user: name=telegraf
        shell=/bin/bash
        group=docker
        append=yes
----

Damit bekommen wir Docker-Monitoring quasi geschenkt. Wir werden später noch detaillierter darauf zurückkommen, für
den Anfang ist das aber bereits ziemlich praktisch.
Wir legen hierfür drei neue Graphen an.

- Anzahl der Images / Host
- Anzahl der Container / Host
- Anzahl der Bytes, die übers Netzwerk vom jeweiligen Host geschickt / gelesen werden.

image::/assets/images/03_docker_monitoring.png[Docker Monitoring, 800]

Das angepasste Dashboard ist http://{{site.url}}/assets/dashboards/systems-dashboard-simple-1.json[hier] hinterlegt.

=== Docker Upgrade

Über Ansible lässt sich jetzt auch problemlos die Docker-Version upgraden. Der Release-Zyklus von Docker ist teilweise schneller als der des Kernel-Images auf den jeweiligen Nodes.
Wir wollen also die Möglichkeit, Docker unabhängig vom Kernel-Image upzudaten.

Hierfür definieren wir eine neue Rolle _docker-host_, die einem Host zugeordnet wird, auf dem Docker betrieben wird.
Sollten wir also die notwendigkeit haben, die Docker-Version zu aktualisieren (auf beispielsweise eine Preview-Version, wie beispielsweise jetzt auf die _hippe_ Version 1.12), dann muss hierfür ab jetzt nur noch die URL auf das Binary aktualisiert werden, die Version wird dann automatisch auf allen Knoten installiert.

Die Schritte zum Installieren einer neuen Docker-Version legen wir wie gewohnt in der _tasks.yml_ fest.

- Docker-Paket laden
- Aktuelle Docker-Version deinstallieren
- Neues Docker-Paket installieren

[source, bash]
----
---
- name: get docker
  get_url: url={{docker_uri}} dest=/tmp/docker.deb  mode=0740 timeout=250
- name: uninstall existing docker
  apt: name=docker-hypriot purge=no state=absent
- name: install docker
  apt: deb=/tmp/docker.deb
----

Die Latest-Binaries bekommt man beispielsweise direkt vom Hypriot-Jenkins footnote:[https://jenkins.hypriot.com/job/armhf-docker/20/artifact/bundles/latest/build-deb/debian-jessie/[Hypriot-Jenkins]] serviert.

Die URL auf das Binary hinterlegen wir in der _main.yml_ im Ordner _vars_.

[source, bash]
----
docker_uri: https://jenkins.hypriot.com/...deb
----

Als letzten Schritt definieren wir im _nodes_-Playbook, dass ein _Node_ sowohl überwacht wird als auch Docker installiert haben sollte. Wir haben bisher keine anderen Anforderungen an einen Node im Cluster.

[source, bash]
----
---
- hosts: nodes
  become: yes
  #only one node at a time
  #serial: 1
  roles:
  - metered-node
  - docker-host <1>
----
<1> Jeder Knoten hat die Rolle _docker_host_ inne.


=== Ansible Tags

Mit dem jetzigen Setup wird jedesmal, wenn wir das Playbook starten überprüft, ob für Telegraf etwas zu tun ist und auch ob evtl. eine neue Docker-Version installiert werden muss.
Für neue Nodes im Cluster ist das ideal, denn das Playbook kümmert sich um alles.
Für existierende Nodes kann das gerade bei größeren Playbooks sehr zeitaufwendig werden.

Ansible erlaubt es, Rollen und Konfigurationen mit Tags zu verstehen. Tags erlauben uns, beim Ausführen eines Playbooks nur bestimmte Teile auszuführen, beispielsweise eben nur die Installation einer neuen Docker-Version.

=== Fazit

Damit haben wir ziemlich viel geschafft. Erstmals sehen wir wirklich, wie es den Hosts im Cluster geht. Wir _sehen_
im Dashboard, dass sich quasi alle Knoten bis auf _pi25_ langweilen, weil bisher nichts auf den Knoten deployed wurde.

Im folgenden Dashboard sieht man beispielsweise genau, wie sich das System verhält, wenn ungenutzte Docker-Images
oder gestoppte Container entfernt werden. Die CPU Last steigt kurz stark an um dann wieder stark abzufallen.

image::/assets/images/03_dashboard.png[Dashboard, 800]

Damit haben wir den Grundstein gelegt für ein gesundes und stabiles System. Wann immer neue Komponenten ins System
eingebracht werden lässt sich an den Graphen sofort erkennen, wie sich das auf das gesamte Ökosystem auswirkt.
Wir sind nicht länger blind und müssen auf unsere Intuition vertrauen, wir verlassen uns stattdessen auf harte
Fakten, Graphen und Statistik.

Wie aber bekommen wir jetzt mit, wann sich kritische Änderungen im System ergeben?
Müssen wir ständig auf die Dashboards blicken um im geeigneten Moment reagieren zu können?
Eher nicht... Stattdessen legen wir Schwellwerte fest, bei dere
n Erreichen das System uns benachrichtigen soll.
Hierfür verwenden wir ein weiteres System aus dem Influx-Universum. Mehr dazu im nächsten Artikel.


