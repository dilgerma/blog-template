---
layout: default
title: Microservices auf Commodity Hardware Teil 4 - Alerting
shortTitle: Microservices und Commodity Hardware Teil 4
documentationExpanded: false
comments: true
postsExpanded: true
categories: microservices spring-boot distributed-systems
published: true
excerpt: excerpt
root: ../../
---

= Scaling out Microservices - Verteilte Systeme auf einfachster Hardware - Teil 4 - Alerting

== Kapacitor

Im letzten Kapitel haben wir die Nodes in unserem Cluster mit Ansible provisioniert und die wichtigesten Metriken für
 die Systeme in einem Grafana-Dashboard visualisiert.
In diesem Artikel geht es jetzt darum, Probleme im System automatisch zu erkennen und darauf zu reagieren.
Kapacitor ist das *K* im TICK-Stack von InfluxData. Es ist das Data-Processing Tool, mit dem wir große
Datenmengen bearbeiten können, Anomalien finden und Alarme an die richtigen Ansprechpartner weiterleiten können.

Genau wie wir es bereits mit der InfluxDB gemacht haben möchten wir Kapacitor nicht fest auf einem bestimmten Knoten
installieren sondern wir möchten gerne mit Docker arbeiten.
Derzeit gibt es für die ARM-Plattform noch kein offizielles Image für Kapacitor, was natürlich kein Hindernis ist,
denn unter https://hub.docker.com/r/dilgerm/rpi-kapacitor liegen für Raspberry gebaute Images bereit.

Um Kapactor zu starten loggen wir uns am einfachsten wieder auf einem Rasperry-PI ein (das muss nicht zwingend
derselbe sein, auf dem die InfluxDB läuft).

[source, bash]
----
docker run -d --name kapacitor
    -p 9092:9092 <1>
    -e KAPACITOR_HOSTNAME=192.168.178.25 <2>
    -e KAPACITOR_REPORTING_ENABLED=false
    -e KAPACITOR_INFLUXDB_0_URLS_0=http://192.168.178.25:8086 <3>
   dilgerm/rpi-kapacitor:1.0.0_beta1_1
----
<1> Wir lassen Kapacitor vorerst auf dem Standardport 9092 laufen.
<2> Kapacitor muss seinen eigenen Hostnamen kennen. Der hier konfigurierte Hostname muss für InfluxDB erreichbar sein.
<3> URLs auf InfluxDB Instanzen, mit denen Kapacitor arbeiten soll.

Sofort beim Start registriert Kapacitor sogenannte _Subscriptions_ auf alle Influx-Datenbanken. Soll das auf
bestimmte Datenbanken eingeschränkt werden kann das später konfigurativ gelöst werden.
Wir können sofort prüfen, ob die Verbindung von Kapacitor zur InfluxDB funktioniert, indem wir auf der
Influx-Oberfläche mit der Query _SHOW SUBSCRIPTIONS_ prüfen, ob die Subscriptions angelegt wurden.

image::/assets/images/04_subscriptions.png[Subscriptions, 800]

Eine Subscription in Influx ist ein bisher nur spärlich dokumentiertes Feature. Eine Subscription wird auf eine
Datenbank und Retention-Policy registriert (Retention-Policies werden wir später noch genauer besprechen).
Für jede registrierte Subscription sendet InfluxDB jeden Datenpunkt für die konfigurierte Datenbank /
Retention-Policy an die in der Subscription hinterlegte Zieladresse, in diesem Fall einen HTTP-Endpunkt von Kapactor.

Influx speichert also die Daten und leitet sich gleichzeitig an Kapacitor zur weiteren Verarbeitung.
Kapacitor kann zwar auch selbst über Queries mit Daten aus der Influx arbeiten, für Streaming-Operation sind
Subscriptions aber viel komfortabler.

== Stell dir vor, die Platte ist voll und keiner merkts...

Ein einfaches Beispiel - aktuell habe wir nur wenige Services, die laufen. CPU-Last sollte also zum derzeitigen
Zeitpunkt kein Problem sein (abgesehen vielleicht von dem einen Knoten in meinem Beispiel, auf dem InfluxDB, Kapactor
und Telegraf gleichzeit laufen).

Was aber durchaus ein Problem werden kann, vor allem zusammen mit _Docker_ ist Plattenplatz.

Der _Status Quo_ ist schon teilweise besorgniserregend, denn der Knoten _Pi25_ ist schon nahe an der Kapazität der
Speicherkarte.

image::/assets/images/04_disc.png[Disc, 800]

Es ist natürlich schön, wenn wir das grafisch schon aufbereitet sehen. Was aber, wenn wir eben nicht rechtzeitig in
Grafana darauf aufmerksam werden. Viel praktischer wäre es, wenn wir einfach proaktiv benachrichtigt würden, sobald eine
kritische Schwelle beim verfügbaren Plattenplatz unterschritten wird.

Kapacitor arbeitet ähnlich wie Docker. Wir starten den Service auf einem der Knoten und können dann über einen Client
 darauf zugreifen. Kapacitor hat eine recht sprechende REST-Api, komfortabler ist aber tatsächlich die Arbeit mit dem
  Clienten.

Hierfür laden wir uns das für unser System passende Standalone-Paket von der https://influxdata.com/downloads/#kapacitor[Kapacitor Download Page] herunter. Wir werden nichts auf unserem System installieren sondern möchten nur das Client-Binary aus dem Paket.

Der Client ist die Datei _kapacitor_ und befindet sich im ausgepackten Paket unter _usr/bin_.

Zunächst definieren wir um komfortabel arbeiten zu können in einer Konsole die Umgebungsvariable _KAPACITOR_URL_.

[source, bash]
----
export KAPACITOR_URL = http://192.168.178.25:9092 <1>
----
<1> Unter der Annahme, dass auch bei Ihnen Kapactor unter dem Port 9092 gemapped ist.

Als nächsten Schritt überprüfen wir die Verbindung zu Kapacitor.

[source, bash]
----
./kapacitor stats general
ClusterID:                    e4113e62-9072-4399-b5a7-55ff58257a8c
ServerID:                     58d25e70-381d-4e2e-8f9d-9c4508a1ebc5
Host:                         192.168.178.25
Tasks:                        0
Enabled Tasks:                0
Subscriptions:                0
Version:                      1.0.0~beta1
----

Kapacitor arbeitet mit einer eigenen DSL (TICKScript), die es auf relativ komfortable Weise erlaubt, komplexe Tasks
zu definieren.
Eine wirklich umfangreiche Dokumentation hierzu findet sich auf der https://docs.influxdata.com/kapacitor[offiziellen
 Kapacitor-Seite].

Zunächst einmal müssen wir in der InfluxDB überprüfen, welche Serie und welche Messpunkte für den Alert überhaupt in
Frage kommen. Wir müssen wissen, wieviel Platz auf der Platte noch verfügbar ist und schön wäre auch zu wissen, ob noch genügend _INodes_ zur Verfügung stehen. Beides bekommen wir problemlos über die Metriken von Telegraf in der Serie _disk_.

[source, bash]
----
select free, total, inodes_free, inodes_total from disk group by "host" limit 1
----

Gibt uns beispielsweise folgende Ausgabe für den _Pi25_.

[cols="5*"]

|===
|time
|free
|total
|inodes_free
|inodes_total

|2016-06-25T06:18:50Z
|5825929216
|14865620992
|3041905
|3762304
|===


Ein einfaches Beispiel für einen Alert bei zu wenig Speicher wäre folgendes kleines Script:

[source, bash]
----
stream
   |from().measurement('disk') <1>
   |where(lambda: "fstype" == 'ext4') <2>
   |groupBy('host') <3>
   |alert().
      id('disk_free - {{index .Tags "host"}}').
      message('low disk space  - {{ .Level}} - free {{ index .Fields "used_percent" }}%. Host: {{index .Tags "host"}}').
      warn(lambda: "used_percent" < 70). <4>
      crit(lambda: "used_percent" < 90). <5>
      stateChangesOnly(1h).  <6>
      exec('echo') <7>
----
<1> Zunächst legen wir fest, welche Serie betrachtet werden soll
<2> Filtern auf bestimmten Typ (könnte sich bei Ihnen unterscheiden..)
<3> gruppieren nach host
<4> Schwellwert für Warnungen: 70% Plattenplatz verbraucht
<5> Schwellwert für Crititals: 90% Plattenplatz verbraucht
<6> Reports nur einmal pro Stunde und bei Statusänderungen
<7> Alerts vorerst nur auf Stdout

Wir speichern das Script in einer Datei _disk_free.tick_.

TIP: Kapactor ist sehr streng bei der Verwendung von String-Quotes und Double-Quotes.
Single-Quote definiert ein String-Literal, Doube-Quotes ein Feld in einer Serie.

Über den Client lässt sich das Skript ganz einfach einspielen.

[source, bash]
----
./kapacitor define disk_free <1>
            -type stream  <2>
            -tick disk_free.tick <3>
            -dbrp "telegraf.default" <4>
----
<1> Name des Alarms
<2> Type (stream oder bulk)
<3> Datei mit dem Skript, die übertragen werden soll
<4> Database Retention Policy, deren Stream überwacht werden soll

Wir können uns direkt die in Kapacitor definierten Tasks anzeigen lassen.

[source, bash]
----
./kapacitor list tasks
ID                            Type      Status    Executing Databases and Retention Policies
disk_free                     stream    disabled  false     ["telegraf"."default"]
----

Kapacitor bietet ein eingebautes Test-System um Alerts testen zu können, bevor man sie aktiviert.
Hierfür machen wir ein sogenanntes Recording - Kapacitor erlaubt es uns, für einen definierten Task einen Stream eine
 definierten Zeitraum mitzuschneiden.

[source, bash]
----
./kapacitor record stream -task disk_free -duration 20s <1>
----
<1> Prosa: Schneide 20 sekunden lang den Stream mit für den Task _disk_free_ und gib bescheid, wenn du damit fertig
bist.

Die Aufnahmen kann man sich anzeigen lassen.

[source, bash]
----
./kapacitor list recordings
ID                                      Type    Status    Size      Date
35fad4a5-9468-4b48-836b-a4cb573c5da4    stream  finished  1.5 kB    26 Jun 16 14:34 CEST
----
exit
TIP: Die Größe sollte nicht 0Kb sein, das ist ein Indiz, dass etwas mit der Verbindung zur InfluxDB oder dem Rückkanal
nicht stimmt.

Sobald der aufgezeichnete Stream zur Verfügung steht können wir das testen, in dem wir den Stream einfach nochmal
abspielen lassen.
Auf diese Art und Weise können wir einen Task mit einem definierten Datensatz testen, ohne ihn aktivieren zu müssen.

In einer zweiten Konsole loggen wir uns per SSH auf dem Node ein, auf dem Kapacitor läuft.
Wir holen uns die ID des Containers mit Hilfe von _docker ps_ und tailen anschließend die Logs.

[source, bash]
----
ssh pirate@pi25

docker ps

...
docker logs --tail=20 -f f798bda83a2c
----

Sobald wir die Logs im Blick haben können wir ein Replay starten.

CAUTION: Sie machen das natürlich dort, wo sie den Kapacitor-Client haben.

[source, bash]
----
./kapacitor list recordings
./kapacitor replay -recording <recording-id> -task disk_free
----

Sobald Sie das Replay laufen lassen beobachten Sie die Log-Ausgabe.

[source, bash]
----
[task_master:74e19221-2c2e-43d6-98a2-209078781893] 2016/06/26 15:28:15 I! Started task: disk_free
[task_master:74e19221-2c2e-43d6-98a2-209078781893] 2016/06/26 15:28:15 I! Stopped task: disk_free
[task_master:74e19221-2c2e-43d6-98a2-209078781893] 2016/06/26 15:28:15 I! closed
----

Durch das _echo_ sehen wir die Abarbeitung des Tasks während des Replays, aber keinen Alert.
Aktuell ist kein Node im kritischen Zustand.
Wir können das aber problemlos testen, indem wir die Schwellwerte einfach kurz testweise heruntersetzen,
beispielsweise auf 50.

TIP: Editieren Sie die Datei disk_free.tick so, dass ein Schwellwert überschritten wird. Sie finden die notwendigen
Daten, wenn Sie in der Influx-UI die Query _select used_percent from disk where fstype="ext4" group by host limit 1_
absetzen.

image::/assets/images/04_threshold.png[Threshold, 800:wq!]

Spielen Sie anschließend die Daten erneut ein.

[source, bash]
----
./kapacitor define disk_free
            -type stream
            -tick disk_free.tick
            -dbrp "telegraf.default"
----

TIP: Sie können einen Task so oft einspielen wie Sie möchten und überschreiben damit einfach die vorige Definition.

Lassen Sie anschließend erneut das _Replay_ laufen. Behalten Sie dabei die Konsole im Auge.

[source, bash]
----
./kapacitor replay -recording <recording-id> -task disk_free

#konsolenausgabe

WARNING alert triggered id:disk_free - pi25 msg:low disk space  - WARNING - Belegt: 59.38668137042572%WARNING alert triggered id:disk_free - pi25 msg:low disk space :::  - WARNING - Belegt: 59.38668137042572%
 [...]
----

TIP: Damit Alerts geloggt werden muss Kapacitor mit Log-Level Debug laufen.

Tatsächlich sehen wir hier unseren ersten Alert mit Severity "WARNING", der wegen zu geringem Speicherplatz ausgelöst
 wurde. Es bleibt uns jetzt offen, was wir damit machen.
Es gibt unzählige Möglichkeiten:
- Senden einer E-Mail
- Senden von Textnachrichten
- Verwendung eines der vielen Messaging-Solutions, die nativ unterstützt werden (Sensu, VictorOps..)

Sobald wir zufrieden sind mit der Konfiguration können wir den Task aktivieren und erhalten fortan echte Alerts aus
dem Telegraf-Stream sollte die Platte voll laufen.

[source, bash]
----
./kapacitor enable disk_free
----

=== E-Mail Alert

Falls Sie das Reporting per E-Mail ausprobieren möchten geht das sehr einfach.

Zunächst benötigen Sie eine Konfiguration für Kapacitor, die Sie sich am besten aus der laufenden Kapacitor-Instanz
erzeugen lassen.

Loggen Sie sich hierfür auf dem Node ein und finden Sie die ID des laufenden Kapacitor-Containers.

[source, bash]
----
docker ps

#
docker exec -ti <container-id>  kapacitord config >> kapacitor-test-config.conf
----

Editieren Sie die Konfigurationsdatei und befüllen Sie den Abschnitt für SMTP.

[source, bash]
----
[smtp]
  enabled = false
  host = "localhost"
  port = 25
  username = ""
  password = ""
  no-verify = false
  global = false
  state-changes-only = false
  from = ""
  idle-timeout = "30s"
----

Es empfiehlt sich außerdem, in der Log-Sektion das File-Logging zu deaktivieren, was die Arbeit mit Docker extrem
vereinfacht.

[source, bash]
----
[logging]
  #file = "/var/log/kapacitor/kapacitor.log" <1>
  level = "DEBUG"
----
<1> File-Logging deaktivieren - Logging auf StdOut

Starten Sie Kapacitor mit dieser Konfiguration.

[source, bash]
----
docker run -d
    --name kapacitor
    -p 9092:9092
    -v kapacitor.conf:/kapacitor.conf <1>
    dilgerm/rpi-kapacitor:1.0.0_beta1_1
    -config  /kapacitor.conf <2>
----
<1> Mounten Sie die Konfiguration in den Container
<2> Übergeben Sie die zu verwendenden Konfiguration als Startparameter

Zu guter letzt aktivieren wir neben dem regulären Logging noch den E-Mail Alert in der Task-Definition _disk_free
.tick_ und übertragen die neue Task-Definition anschließend erneut zu Kapacitor.

[source, bash]
----
stream
   |from().measurement('disk')
   |where(lambda: "fstype" == 'ext4')
   |groupBy('host')
   |alert().
      id('disk_free - {{index .Tags "host"}}').
      message('low disk space  - {{ .Level}} - Belegt: {{ index .Fields "used_percent" }}%. Host: {{index .Tags "host"}}').
      warn(lambda: "used_percent" > 50).
      crit(lambda: "used_percent" > 90).
      stateChangesOnly(1h).
      email().to('<your e-mail address>') <1>
----
<1> E-Mail Alerts

Anschließend laden wir den Task neu.

[source, bash]
----
./kapacitor reload disk_free
----

Direkt nach dem Reload sollte eine E-Mail gesendet werden.
Falls nein, prüfen Sie die Logs.

Sauberer wäre es sogar, die Konfiguration in einem  _Data-Container_ abzulegen und diesen zu referenzieren.

[source, bash]
----
docker create -v /tmp/kapacitor.conf:/kapacitor.conf --name kapacitor-data resin/rpi-raspbian:jessie /bin/true

#funktioniert selbst noch, nachdem das /tmp-Verzeichnis geleert wurde:)
docker run -d --name kapacitor -p 9092:9092 --volumes-from kapacitor-data dilgerm/rpi-kapacitor:1.0.0_beta1_1 -config /kapacitor.conf
----

== Fazit

Mit Kapacitor haben wir ein erstaunlich einfach zu verwendendes Tool an der Hand, das es uns erlaubt, sowohl
Stream-Processing als auch Bulk-Operationen auf den Daten einer InfluxDB durchzuführen.
Ein einfaches Alerting ist schnell eingerichtet und auch das Generieren ganz neuer Daten als Aggregation eines
Streams ist möglich.

Wir werden die Verwendung von Kapacitor noch weit ausbauen, doch das ist etwas für spätere Kapitel.

Wir haben jetzt einen Cluster aus einer ganzen Menge Knoten, haben ein sauberes Monitoring für den ganzen Cluster und
 sehen, auf einen Blick was aufvden einzelnen Maschinen passiert.
Zusätzlich haben wir jetzt ein einfaches Alerting, das uns aktuell benachrichtit, sobald eine Platte vollläuft.

Wir können in diesem Fall manuell gegensteuern oder beispielsweise direkt von Kapactor ein Skript starten lassen, das
 beispielsweise Docker-Images und nicht mehr gebrauchte Container weg räumt.

 Im nächsten Kapitel geht es endlich um den ersten _echten_ Microservice unseres Stacks. Bisher haben wir keinerlei
 Busines-Value generiert sondern nur Vorarbeit um sauber mit dem Stack arbeiten zu können. Das ändert sich sofort im
 nächsten Kapitel.