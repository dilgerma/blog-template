---
layout: default
title: Microservices auf Commodity Hardware Teil 5 - Ein erster Service
shortTitle: Microservices und Commodity Hardware Teil 5
documentationExpanded: false
comments: true
postsExpanded: true
categories: microservices spring-boot distributed-systems
published: true
excerpt: excerpt
root: ../../
---

= Scaling out Microservices - Verteilte Systeme auf einfachster Hardware - Teil 5 - Ein erster Service

In den letzten Kapiteln haben wir uns intensiv mit Monitoring unserer Serverlandschaft beschäftig. Der Vorteil liegt
klar auf der Hand - wir sind jetzt alles andere als blind und sehen sofort, wenn beispielsweise eine neu deployte
Applikation zu viel Serverlast erzeugt oder die Log-Files die komplette Platte verstopfen.

Der Business-Value den wir bisher geliefert haben geht aber gegen null.

== Beschreibung der Anwendung

Ich bin Freelancer und arbeite in unterschiedlichen Projekten. Jedes dieser Projekte erwartet von mir, dass ich der
einen oder anderen Form meine Zeiten tracke. Ich mache das also pro Projekt und nochmals für meine eigene Buchhaltung
 und für die Rechnungsstellung am Monatesende.

Im Laufe dieses Artikels werden wir die kleine Anwendung _billy time_ auf Basis von Spring-Boot entwickeln, die
zunächst nichts weiter als eine kleine REST-API bereitstellen wird um Zeiten für Projekte zu tracken.
Wir werden die Anwendung außerdem verwenden um das Applikationsmonitoring zu testen und zu konfigurieren, denn fast
noch wichtiger als der Zustand der einzelnen Serverknoten ist der Zustand der Applikation selbst. Probleme mit der
Hardware lassen sich meisten recht zeitnah mit ein wenig Budget und zusätzlicher Hardware erschlagen. Probleme in der
 Software sind viel schwerer zu entdecken und zu beheben, daher ist es unser Ziel von Anfang an ein sauberes
 Applikationsmonitoring zu haben.

Wir werden für diese Anwendung mit Spring und Spring-Boot arbeiten. Kennen Sie die Frameworks bisher nicht ist jetzt
eine wunderbare Gelegenheit, sich damit vertraut zu machen.

== Spring Boot

Spring Boot ist ein Projekt, dass in den letzten Monaten und Jahren (zu Recht!) extrem an Zulauf gewonnen hat, da es
sich zum Ziel gemacht hat, die Arbeit mit dem Springframework so einfach und komfortabel wie möglich zu machen.
Bevor wir lange diskutieren erzeugen wir uns einfach ein Application-Skeleton.

Das Projekt ist auf https://github.com/dilgerma/billy-rpi-time.git[github] gehostet.

Ein Stub lässt sich ganz einfach mit wget erzeugen, asnchließend entpacken und dann bauen. Sie müssen hierfür nicht
mal http://gradle.org/[Gradle] installieren.

[source, bash]
----
wget -O app.zip http://bit.ly/29gWMT3
#
unzip ...
#
./gradlew build
----

Das erste Starten der Anwendung geht sogar noch einfacher.

[source, bash]
----
./gradlew bootRun
# ...
Started BillyTimeApplication in 3.979 seconds (JVM running for 4.381)
----

Die Anwendung läuft jetzt auf dem Port 8080.
Öffnen Sie im Browser die Anwendung unter _http://localhost:8080_, sie kann aber leider noch nichts.

Wir öffnen die Anwendung mit einer Entwicklungumgebung und definieren einen ersten einfachen Rest-Controller.

[source, java]
----
@RestController
public class TimeTrackingResource {

    @RequestMapping("projects")
    public List<String> projects() {
        return Arrays.asList("project1", "project", "project3");
    }
}
----

Starten Sie die Anwendung anschließend erneut, entweder wieder aus der Konsole oder aus der Entwicklungsumgebung direkt.

Laden Sie die Projektliste mit cURL.

[source, bash]
----
curl http://localhost:8080/projects
["project1", "project", "project3"]
----

Herzlichen Glückwunsch, damit haben wir die erste funktionsfähige Anwendung mit _Spring Boot_ entwickelt.

=== Actuator

_Actuator_ bietet laut http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#production-ready[eigener Dokumentation] production-ready Metriken für _Spring Boot Applikationen.

_Actuator_ bietet einfach zu konfigurierendes Monitoring, Metriken und Health-Checks und wird einfach aktiviert,
indem die entsprechende Dependency deklariert wird. Haben Sie sich das Projekt über die obige URL generieren lassen
ist alles schon bereit, falls nein deklarieren Sie in der build.gradle einfach die Dependency.

[source, bash]
----
compile('org.springframework.boot:spring-boot-starter-actuator')
----

Actuator bietet die folgenden Endpunkte.

==== Health

Unter dem Kontextpfad "/health" lassen sich Daten zu den in der Anwendung definierten Health-Checks abrufen.
Die Anwendung ist also _healthy_, wenn sie genügend Plattenplatz hat.

[source, bash]
----
 curl http://localhost:8080/health

{
    "status": "UP",
    "diskSpace": {
        "status": "UP",
        "total": 499071844352,
        "free": 114422198272,
        "threshold": 10485760
    }
}
----

Denkbar wäre hier natürlich, dass die Anwendung _healthy_ ist, wenn alle abhängigen Services _healthy_ sind, wenn die
 Datenbank erreichbar ist etc.

Der nächste Endpunkt ist der Info-Endpoint unter "/info".

==== Environment

Unter "/env" lassen sich Informationen zum Environment abrufen.

[source, bash]
----
 curl http://localhost:8080/env
----

Unter diesem Endpunkt finden sich alle Konfigurationen (Properties, System-Variablen etc).

==== Metriken

Spring Boot überwacht mit Actuator alle REST-Endpunkte und stellt Metriken bereit. Diese können unter dem Endpunkt
"/metrics" abgerufen werden.

[source, bash]
----
curl http://localhost:8080/metrics
#
{
    "mem": 368372,
    "mem.free": 146319,
    "processors": 8,
    "instance.uptime": 364586,
    "uptime": 368888,
    "gauge.response.env": 16.0,
    "gauge.response.health": 87.0,
    "gauge.response.info": 5.0,
    "counter.status.200.info": 1,
    "counter.status.200.health": 1,
    "counter.status.200.env": 1
}
----

==== Trace

Mit Trace lässt sich verfolgen, welche Requests die Anwendung verarbeitet hat.

[source, bash]
----
curl http://localhost:8080/curl
[
    {
        "timestamp": 1467048531190,
        "info": {
            "method": "GET",
            "path": "/metrics",
            "headers": {
                "request": {
                    "host": "localhost:8080",
                    "user-agent": "curl/7.43.0",
                    "accept": "*/*"
                },
                "response": {
                    "X-Application-Context": "application",
                    "Content-Type": "application/json;charset=UTF-8",
                    "Transfer-Encoding": "chunked",
                    "Date": "Mon, 27 Jun 2016 17:28:51 GMT",
                    "status": "200"
                }
            }
        }
    }
]
----

Spring-Boot merkt sich per Default die letzten 100 verarbeiteten Requests.

=== DropWizard Metrics

Die Actuator-Metriken und viele, viele weitere Metriken die wir noch sammeln werden müssen wir persistieren, denn nur
 wenn wir die Daten mit ihrem historischen Kontext analysieren können sehen wir, wie sich die Anwendung über den Lauf
  der Zeit entwickelt hat.

Hierfür nutzen wir natürlich die Tools, die wir bereits im Einsatz haben.
Metriken werden in die InfluxDB übertragen, Alerting für jede Applikation machen wir mit Kapacitor.
Wir aber bekommen wir die Daten möglichst unkompliziert in die InfluxDB?

Zunächst definieren wir die Abhängigkeit auf die http://metrics.dropwizard.io/3.1.0[DropWizard-Metrics Bibliothek], ein quasi Standard, wenn auch schon leicht angegraut.

TIP: Das letzte Release dieser Library war im September 2014, also bald 2 Jahre her. Wir werden deshalb später nicht
mehr mit einem offiziellen Release arbeiten sondern mit jitpack.io[JitPack], um auf die letzten Stand zugreifen zu können.

Wir definieren eine Abhängigkeit auf Metrics in der build.gradle.

[source, bash]
----
compile 'io.dropwizard.metrics:metrics-core:3.1.0'
----

Zusätzlich brauchen wir einen Reporter, der die Daten in die InfluxDB schreibt. Dafür ist in Metrics 3.1.0 noch kein
Support vorgesehen. Ich habe deshalb einen eigenen Reporter geschrieben, der so einfach wie möglich die Daten in die
Influx überträgt.

[source, bash]
----
compile 'com.github.dilgerma:influxdb-reporter:0.0.4'
----

Damit das funktioniert müssen wir zusätzlich Jitpack als Repository aktivieren.

[source, bash]
----
repositories {
	mavenCentral()
	maven { url "https://jitpack.io" }
}
----

Hier nochmal der Vollständigkeit halber die komplette _build.gradle_.

[source, bash]
----
buildscript {
	ext {
		springBootVersion = '1.3.5.RELEASE'
	}
	repositories {
		mavenCentral()
	}
	dependencies {
		classpath("org.springframework.boot:spring-boot-gradle-plugin:${springBootVersion}")
	}
}

apply plugin: 'java'
apply plugin: 'spring-boot'

jar {
	baseName = 'billy-time'
	version = '0.0.1-SNAPSHOT'
}
sourceCompatibility = 1.8
targetCompatibility = 1.8

repositories {
	mavenCentral()
	maven { url "https://jitpack.io" }
}


dependencies {
	compile('org.springframework.boot:spring-boot-starter-actuator')
	compile('org.springframework.boot:spring-boot-devtools')
	compile('org.springframework.boot:spring-boot-starter-hateoas')
	compile('org.projectlombok:lombok:1.16.6')
	compile('org.springframework.boot:spring-boot-starter-web')

	compile 'io.dropwizard.metrics:metrics-core:3.1.0'
	compile 'com.github.dilgerma:influxdb-reporter:0.0.6'

	testCompile('org.springframework.boot:spring-boot-starter-test')
	testCompile('org.springframework.restdocs:spring-restdocs-mockmvc')
}
----

Das war jetzt viel Vorarbeit und bisher haben wir noch keinen Nutzen daraus gezogen.

Zuletzt aktivieren wir den InfluxReporter, indem wir ihn konfigurieren und unter die Kontrolle von _Spring_ stellen.
Hierfür definieren wir eine Configuration-Klasse, die die Konfiguration des Reporters übernimmt. Generell ist es eine
 gute Idee, Konfigurationen für die Anwendung sauber in einzelne Konfigurationsblöcke (und damit
 Configuration-Klassen) aufzuteilen.
Zunächst definieren wir die notwendigen Properties in der _application.properties_, die die Konfiguration beschreiben.

[source, bash]
----
spring.application.name=billy-time
deployment.environment=local <1>

influxdb.url=http://192.168.178.25:8086 <2>
influxdb.username= <3>
influxdb.password= <4>
influxdb.database=billy_time_metrics <5>

metrics.serviceName=${spring.application.name} <6>
metrics.host=${hostname} <7>
metrics.environment=${deployment.environment} <78>
metrics.scheduleSeconds=5 <9>
----
<1> Die Umgebung - per default auf _local_ gestellt
<2> URL der InfluxDB - das sollte später noch dynamischer werden
<3> Username für den Zugriff auf die InfluxDB, bei uns leer
<4> Passwort für den Zugriff auf die InfluxDB, bei uns leer
<5> Die Datenbank, in der die Metriken für diesen Service gespeichert werden
<6> Ein Human-Readable-Name für diese Anwendung / diesen Service
<7> Der Hostname - wird einfach über die Expression ${hostname} aus der Umgebung gezogen.
<8> Ein eindeutiger Bezeichner für das Environment (beispielsweise DEV,STAGE,PROD)
<9> Scheduling-Intervall - wie oft werden die Daten in die InfluxDB geflushed.

Wir haben also sowohl InfluxDB-spezifische Konfigurationen als auch Meta-Informationen für Metriken, beispielsweise
aus welcher Umgebung kommen diese Metriken und von welchem Service.

Als nächstes nehmen wir die notwendigen Konfiguarationen für Metrics und den Influx-Reporter in der
Configuration-Klasse vor.

Zunächst definieren wir die Klasse _MetricsConfig_ und annotieren sie mit _@Configuration_, damit Spring erkennt,
dass diese Klassen Beans, Services und Konfigurationen bereitstellt.

[source, bash]
----
@Configuration
public class MetricsConfig {}
----

Zunächst müssen wir die Properties laden, die wir zuvor in der _application.properties_ definiert haben. Mit
_Spring-Boot_ ist es sehr einfach, Konfiguration typsicher in der Anwendung zu verarbeiten mit sogenannten
Configuration-Properties.

Laden wir zunächst die InfluxDB-spezifischen Properties. Wir verwenden hierfür die Klasse _InfluxConfiguration_ aus
der Influx-Reporter-Library.

[source, bash]
----
@Bean <1>
@ConfigurationProperties(prefix = "influxdb") <2>
public InfluxConfiguration influxConfig() {
    return new InfluxConfiguration();
}
----
<1> Spring erkennt, dass hier eine Konfiguration bereitgestellt wird
<2> Mit @ConfigurationProperties laden wir alle Properties mit einem definiereten Prefix (hier _metrics_) und setzen
diese automatisch in der Klasse die zurückgegeben wird.

Spring lädt also beispielsweise die Property _influxdb.url_, da das Prefix übereinstimmt und setzt den konfigurierten
 Wert _http://192.168.178.25:8086_ in das Attribut _url_ in der Klasse _MetricsProperties_. Man kann sich das wie ein
  automatisches Binding der Properties vorstellen.

Analog definieren wir die Konfigurations-Klasse für die Metrik-spezifischen Properties.

[source, bash]
----
@Bean <1>
@ConfigurationProperties(prefix = "metrics") <2>
public MetricsProperties metricsProperties() {
    return new MetricsProperties();
}
----

Die Klasse MetricsProperties ist ein einfaches POJO und in der Anwendung selbst definiert.

[source, bash]
----
@AllArgsConstructor
@NoArgsConstructor
@Data
public class MetricsProperties {

    private String serviceName;
    private String host;
    private String environment;
    private int scheduleSeconds;
}
----

Als nächstes Konfigurieren wir die Verbindung zur InfluxDB. Hierfür verwenden wir die Client-Library für Java.

[source, bash]
----
@Bean
public InfluxDB influxDb() {
    InfluxConfiguration influxConfiguration = influxConfig();
    return InfluxDBFactory.
                  connect(influxConfiguration.getUrl(),
                  influxConfiguration.getUsername(),
                  influxConfiguration.getPassword());
}
----

Der Influx-Reporter erlaubt optional die Bereitstellung eines sogenannten _InfoProviders_, der wichtige MetaDaten wie
den Hostnamen, den Anwendungsnamen oder die Umgebung als Tags mit in die InfluxDB schreibt. Wir werden uns in kurzer
Zeit sehr intensiv mit diesem Mechanismus und Influx-Tags beschäftigen.

[source, bash]
----
@Bean
public InfoProvider serviceInfoProvider() {
    MetricsProperties properties = metricsProperties(); <1>
    return () -> ServiceInfo
                .builder()
                .serviceName(properties.getServiceName())
                .host(properties.getHost())
                .environment(properties.getEnvironment())
                .build();
}
----
<1> Der InfoProvider wird aus den MetricsProperties befüllt.

Zuletzt konfigurieren wir den InfluxReporter selbst, der die Metrik-Daten in die InfluxDB überträgt.

[source, bash]
----
@Bean
public InfluxReporter influxReporter() {
    InfluxDB influxDB = influxDb();
    InfluxConfiguration influxConfiguration = influxConfig();
    MetricsProperties properties = metricsProperties();

    return new InfluxReporter(metricRegistry,
            properties.getServiceName(),
            MetricFilter.ALL,
            TimeUnit.MILLISECONDS,
            TimeUnit.MILLISECONDS,
            influxDB,
            influxConfiguration.getDatabase(),
            Optional.of(serviceInfoProvider()));
}
----

Die Metrics-Library bietet das Konzept eines ScheduledReporters. Diese laufen im Hintergrund und schreiben Daten in
das Zielmedium in einem vordefinierten Intervall.
Der InfluxDb-Reporter ist ebenfalls ein ScheduledReporter und läuft während der Entwicklung in einem 5 Sekunden
Intervall.

TIP: In der Praxis hat sich ein Intervall zwischen 10 und 60 Sekunden bewährt.

Der letzet Schritt für die Vorbereitung besteht jetzt darin, den ScheduledReporter zu starten.
Hierfür verwenden wir eine Methode in der MetricsConfiguration, die mit @PostConstruct annotiert wird.
Diese Methode wird aufgerufen, wenn die Configuration-Klasse initialisiert wurde.

[source, bash]
----
@PostConstruct
public void schedule() {
    MetricsProperties properties = metricsProperties();
    final InfluxReporter reporter = influxReporter();
    reporter.start(properties.getScheduleSeconds(), TimeUnit.SECONDS);
}
----

Damit haben wir alle Konfigurationen vorgenommen um die wichtigsten Grundmetriken der Anwendung zu messen und in der
InfluxDB zu persistieren.

=== Request / Response Metriken

Zunächst starten wir die Anwendung, warten eine kurze Zeit und prüfen anschließend ob die Metriken in die Influx
übertragen wurden.

Nicht ganz unerwartet sehen wir alle 5 Sekunden folgende Meldung.

[source, bash]
----
reporting to influx with InfluxDB : org.influxdb.impl.InfluxDBImpl@cec8b21
sending 0 points
----

Der Reporter läuft zwar periodisch, Metriken selber werden aber noch nicht bereitgestellt, da bisher nichts in der
Anwendung passiert ist.
Versuchen wir einen einfachen cURL-Aufruf.

[source, bash]
----
curl localhost:8080/projects
----

Die Ausgabe ändert sich, denn jetzt werden 2 Messpunkte gesendet.

[source, bash]
----
reporting to influx with InfluxDB : org.influxdb.impl.InfluxDBImpl@cec8b2
sending 2 points
----

Welche Messpunkte sind das aber. Eine einfache Influx-Query gibt uns mehr Informationen.

[source, bash]
----
show measurements <1>

counter.status.200.projects <2>
gauge.response.projects <3>

----
<1> *show measurements* zeigt alle Serien in einer Datenbank
<2> Alle Http-200 Status Codes für den Endpunkt "projects"
<3> Durschnittliche Request-Dauer für den Endpunkt "projects"

Tatsächlich kopiert Spring-Boot die wichtigsten Actuator-Metriken automatisch in die DropWizard-MetricRegistry,
sobald die Bean registriert wird. Die Daten werden also automatisch in die InfluxDB übertragen. Dieser Mechanismus ist
flexibel erweiterbar und wir werden später noch Verwendung davon machen.

Die beiden Metriken, die wir bisher in die InfluxDB übertragen sind sehr wichtig und geben Aufschluss
über die Auslastung der Anwendung. Wir sollten das im Auge behalten, und am besten lässt sich das mit Grafana und einem passenden Dashboard.
Vor allem lässt sich sehr einfach nachverfolgen, wie sich die Anwendung verhält, wenn wir sie gleich ein wenig unter
Last setzen.

=== Grafana Dashboard

Wir öffnen also Grafana und erzeugen zunächst eine neue Datasource.

image::/assets/images/05_datasource.png[Data Source]

Auf Basis dieser Datasource können wir jetzt ein neuen Dashboard _Billy Time_ definieren um die beiden bisher
bekannten Metriken (Anzahl Requests / Durchscnittliche Dauer) zu visualisieren.

TIP: Es bietet sich an, pro Service / Anwendung einen oder mehrere Dashboards und mindestens eine Datasource zu
definieren. Warum eine oder mehrere Datenbanken pro Service? So lassen sich problemlos ganz einfach pro Service
definieren, wie lange Influx die Daten vorhalten soll und wann diese wieder gelöscht werden, um Speicher freizugeben.

image::/assets/images/05_dashoard_request_count.png[Request Count, 800]

Die Visualisierung ist derzeit noch recht eintönig, da wir nach wie vor nur einen einzigen Request auf die Anwendung
abgefeuert hatten.
Das Feld _alias By_ kann verwendet werden, um die Legende eines Graphen zu befüllen. Haben wir nach Tags gruppiert kann
 ein Tag mit _$_<tag-name>_ angesprochen werden. Wir die Metrik also nach einen Tag _host_ gruppiert, so kann für
 jede Metrik von einem Host mit _$tag_host_ die korrekte Legendenbeschriftung angegeben werden.

image::/assets/images/05_dashboard_request_count_visual.png[Request Count, 800]

Die Query für diese Abfrage lautet.

[source, bash]
----
SELECT mean("counter") FROM "counter.status.200.projects" WHERE $timeFilter GROUP BY time($interval), "host" fill(null)
----

Die Variablen _$timeFilter_ und _$interval_ werden von Grafana aus den Einstellgen des Dashboards befüllt.

Ein ähnliches Dashboard definieren wir für die durschnittliche Request-Dauer. Auch diese Metrik dürfte derzeit
nicht besonders spannend sein, das wird sich aber noch ändern.

Die Query dieser Abfrage lautet:

[source, bash]
----
SELECT mean("gauge") FROM "gauge.response.projects" WHERE $timeFilter GROUP BY time($interval), "host" fill(null)
----

image::/assets/images/05_metrics_dashboard.png[Metrics Dashboard, 800]


Viel interessanter werden die Metriken, wenn wir die Anwendung ein wenig unter Last setzen.
Ein sehr schönes und einfaches Tool um eine Webanwendung ein wenig zu stressen ist *Apache Bench*.

==== Apache Bench

Mit https://httpd.apache.org/docs/2.4/programs/ab.html[Apache Bench ] können auf einfache Art und Weise (parallele) Requests gegen Webanwendungen gefeuert werden.

Ein einfacher Aufruf von Apache Bench sieht so aus.

[source, bash]
----
ab -c 2 -n 100 http://localhost:8080/projects
----

Über den Parameter _-c 2_ definieren wir, dass zwei Threads Requests absetzen sollen, über den Parameter _-n 100_
definieren wir, dass 100 Requests abgesetzt werden sollen.

Apache Bench generiert uns einen anschaulichen Report (_hier in Auszügen_).

[source, bash]
----
Concurrency Level:      2
Time taken for tests:   0.142 seconds <1>
Complete requests:      100
Time per request:       2.838 [ms] (mean) <2>
Time per request:       1.419 [ms] (mean, across all concurrent requests)
Transfer rate:          148.66 [Kbytes/sec] received

Percentage of the requests served within a certain time (ms)
  50%      2
  66%      3
  75%      3
  80%      3
  90%      4
  95%      5
  98%      8
  99%      8
 100%      8 (longest request)

----
<1> Der ganze Testlauf hat knapp 0.1  Sekunden gedauert
<2> Durschnittliche Dauer / Request
<3> Hier sehen wir Percentile - der längste Request hat knapp 8 ms gedauert, 99% der Request waren schneller, der nächst langsamste Request war 5 ms, 95% der Requests waren schneller.

image::/assets/images/05_ab_dashboard.png[Apache Bench Test Dashboard, 800]

Im Graphen für die Request-Dauer sieht man einen Schwenk nach unten, fälschlicherweise man könnte jetzt vermuten, die Anwendung wird schneller wenn man sie unter Last setzt. Natürlich stimmt das nicht, denn die erst jetzt haben wir eine genügend große Gruppe um einen brauchbaren Mittelwert zu bilden. Der erste Request war einfach viel langsamer als der Durchschnitt.

Stressen wir die Anwendung erneut mit 1000 Requests und 4 Threads.

[source, bash]
----
ab -c 4 -n 1000 http://localhost:8080/projects

Concurrency Level:      4
Time taken for tests:   0.567 seconds
Complete requests:      1000
Requests per second:    1762.46 [#/sec] (mean)
Time per request:       2.270 [ms] (mean)

Percentage of the requests served within a certain time (ms)
  50%      2
  66%      2
  75%      2
  80%      2
  90%      2
  95%      3
  98%      3
  99%      4
 100%    138 (longest request)
----

image::/assets/images/05_ab_dashboard_02.png[Apache Bench Test Dashboard, 800]

Die durschnittliche Request-Dauer verändert sich nicht.
Was passiert, wenn wir einen Ausreisser haben. Nehmen wir an, wir haben einen Request, der extrem lange dauert, weil
beispielsweise ein Backend-System (das wir vorerst natürlich nur simulieren nicht antwortet und die Timeouts nicht
richtig konfiguriert sind).

Hier setzen wir einfach in unserem RestController einen einfachen Timeout von 10 Sekunden - in der IT Welt eine
Ewigkeit.

[source, bash]
----
@RestController
public class TimeTrackingResource {

    @RequestMapping("projects")
    public List<String> projects() throws Exception {
        if (true) {
            Thread.sleep(10000);
        }
        return Arrays.asList("project1", "project", "project3");
    }
}
----

Starten Sie die Anwendung neu, wir machen nur einen einzigen Request.

[source, bash]
----
curl http://localhost:8080/projects
----

Wir betrachten die Graphen in Grafana erneut.

image::/assets/images/05_ab_dashboard_median.png[Ausreisser, 800]

Ausgehend von dieserm Graphen könnte man jetzt vermuten, die Anwendung wäre langsamer geworden ist.
Die Metrik, die wir hier verwenden ist das _arithmetische Mittel_, also der gemittelte Wert über alle Requests.
Das _Artithmetische Mittel_ ist die mit Sicherheit am häufigsten verwendete Metrik, die aber das Problem hat, dass Ausreisser das Ergebnis massiv verfälschen können.

Betrachten wir die Daten kumuliert über die letzten 15 Minuten.

[source, bash]
----
SELECT mean("gauge") FROM "gauge.response.projects" WHERE $timeFilter GROUP BY time(15m), "host" fill(null)
----

Ergibt sich folgender Graph.

image::/assets/images/05_mean.png[Ausreisser, 800]

Wir hatten also eine durchschnittliche Request-Dauer von 4 Sekunden.

Das Arthmetische Mittel berechnet sich durch die Summe aller Werte im Betrachtungszeitraum geteilt durch die Anzahl der betrachteten Werte. Es gibt die schöne https://introductorystats.wordpress.com/2011/09/04/when-bill-gates-walks-into-a-bar[Geschichte], in der _Bill Gates_ eine Bar betritt. In dieser Bar diskutieren gerade einige Mittelständler über ihr Einkommen.

----
- Hans : 25.000 €
- Georg: 30.000 €
- Max: 45.000 €
- Harald: 50.000 €

Im Mittel verdient die Runde _(25.000 + 30.000 + 45.000 + 50.000) / 4 = 37.500_

_Bill Gates_ diskutiert natürlich mit.

----
- Hans : 25.000 €
- Georg: 30.000 €
- Max: 45.000 €
- Harald: 50.000 €
- Bill: 1.0000.0000.000 €

Plötzlich verdient die Runde im Schnitt statt 37.500 € 200.030.000 €. Die Rechnung ist komplett richtig, nicht aber das was uns hier interessiert. Das Ergebnis ist verzerrt.

Besser ist es in diesem Fall mit dem _Median_ zu arbeiten. Um den Median zu berechnen sortiert man die Werte der Größe nach im Betrachungszeitraum und nimmt den Wert genau in der Mitte, bzw. bei einer geraden Anzahl Werte das Artithmetische  Mittel der beiden Werte in der Mitte.
Der Vorteil des Medians - er wird nicht durch Ausreisser beeinflusst.


Der Median für die gesellige Runde ohne Bill Gates lag bei 37.500 € (das Gehalt von Georg und Max / 2) und entspricht somit genau dem arithmetischen Mittel.
Der Median für die Runde mit Bill Gates liegt bei 45.000 € (das Gehalt von Max). Bill Gates beeinflusst den Median also nur unwesentlich.

Betrachten wir den Median für die Request-Dauer ergibt sich ein viel realistischeres Bild.

[source, bash]
----
SELECT median("gauge") FROM "gauge.response.projects" WHERE $timeFilter GROUP BY time(15m), "host" fill(null)
----

Wird mit dem Median gearbeitet sollte immer auch der Vollständigkeit halber die Standardabweichung mit angegeben werden. Anhand der Standardabweichung lässt sich feststellen, wie sehr die Werte im Durchschnitt vom arithmetischen Mittel abweichen.

[source, bash]
----
SELECT stddev("gauge") FROM "gauge.response.projects" WHERE $timeFilter GROUP BY time(15), "host" fill(null)
----

Der Graph gibt schon einen Hinweis darauf, dass der Mittelwert hier ein verfälschtes Bild widergibt, da die durchschnittliche Request-Dauer (im Graphen des Arithmetischen Mittels) bei knapp 4 Sekunden liegt, die einzelnen Positionen im Schnitt aber bis zu 5 Sekunden abweichen.

image::/assets/images/05_stddev.png[Standardabweichung, 800]

Eine Standardabweichung von 5 Sekunden bei einem Mittelwert von 4 Sekunden besagt, dass es Requests gibt, die nur im Millisekunden-Bereich liegen, aber auch Requests die sehr lange dauern (4 Sek. + 5 Sek. StdDev). Eine Standardabweichung in dieser Größe deutet stark auf ein verfälschtes Ergebnis hin und man sollte zumindest genauer recherchieren.

Das Dashboard zum importieren findet sich unter http://{{site.url}}/assets/dashboards/Billy-Time-dashboard.json.

=== JVM Metriken

Neben dem Request / Response Verhalten der Anwendung ist natürlich auch die Auslastung des Systems von Interessen. Da wir mit der JVM arbeiten sollten wir neben der Speicherauslastung des Knotens über Telegraf zusätzlich die Speicherauslastung der JVM betrachten.

Hierfür definieren wir eine zusätzliche Abhängigkeit in der _build.gradle_.

[source, bash]
----
compile 'io.dropwizard.metrics:metrics-jvm:3.1.0'
----

Daten über Speicher- und Systemauslastung werden standardmäßig nicht von Actuator reportet. Wir greifen auf einige sogenannte _Standard-Metric-Sets_ aus der DropWizard-Library zurück, die uns die Metriken über die JVM bereitstellen. Hierfür registrieren wir in der Klasse _MetricsConfig_ folgende MetricSets.

[source, bash]
----
@Bean
public MetricRegistry metricRegistry() {
     MetricRegistry metricRegistry = new MetricRegistry();
     metricRegistry.registerAll(new JvmAttributeGaugeSet()); <1>
     metricRegistry.registerAll(new MemoryUsageGaugeSet()); <2>
     metricRegistry.registerAll(new GarbageCollectorMetricSet()); <3>
     return metricRegistry;
}
----
<1> Einige JVM Metriken wie _uptime_.
<2> Heap- und Non-Heap Speicherauslastung
<3> Garbage Collection Metriken

Anschließend starten wir die Anwendung erneut.

[source, bash]
----
reporting to influx with InfluxDB : org.influxdb.impl.InfluxDBImpl@1db19a89
d.e.metrics.influx.InfluxReporter        : sending 27 points
----

Es werden jetzt eine ganze Menge Standard-Metriken in die InfluxDB übertragen.

Eine interessante Metrik ist beispielsweise der aktuell verwendete Heap.

[source, bash]
----
SELECT mean("gauge") FROM "heap.used" WHERE $timeFilter GROUP BY time(1m), "host" fill(null)

SELECT stddev("gauge") FROM "heap.used" WHERE $timeFilter GROUP BY time(1m), "host" fill(null)
----

image::/assets/images/05_heapused.png[Heap, 800]

Zusätzlich visualisieren wir die durschnittliche Zeit, die die Anwendung in einem Teil der Garbage Collection verbringt.

[source, bash]
----
SELECT mean("gauge") FROM "PS-MarkSweep.time" WHERE $timeFilter GROUP BY time(1m), "host" fill(null)
----

image::/assets/images/05_gc.png[Heap, 800]

Wenig spannendes - versuchen wir erneut, die Anwendung ein wenig unter Last zu setzen.

Fügen Sie im Restendpoint folgende Zeilen hinzu.

[source, bash]
----
@RequestMapping("projects")
public List<String> projects() throws Exception {
     List<Date> justAStupidDateList = new ArrayList<>();
     IntStream.range(0, 1_000_000).forEach(value -> justAStupidIntList.add(new Date()));
     return Arrays.asList("project1", "project", "project3");
}
----

Für jeden Rest-Request allokieren wir also 1.000.000 (in Worten 1 Million Date-Instanzen in einer Liste, die direkt wieder verworfen werden).
Ohne dass Sie sich die nachfolgenden Metriken anschauen, was passiert wenn wir zunächst einen Request und anschließend mit _Apache Bench_ folgenden Testlauf starten. Wie wirken sich diese beiden Zeilen auf _Request-Dauer_, _Garbage Collection_ und _Heap Usage_ aus?

[source, bash]
----
curl localhost:8080/projects
ab -c 4 -n 1000 http://localhost:8080/projects
----

Der Report liefert das folgende Ergebnis:

[source, bash]
----
Time per request:       61.190 [ms] (mean)

Percentage of the requests served within a certain time (ms)
  50%     54
  66%     55
  75%     57
  80%     59
  90%     78
  95%     89
  98%     98
  99%    119
 100%    742 (longest request)

----

Die Analyse sollte in ungefähr den Erwartungen entsprechen, die JVM arbeitet extrem performant auch bei großen Datenmengen,

image::/assets/images/05_gc_analyse_1.png[GC Analyse, 800]

Entfernen Sie die künstliche Last wieder - die Anwendung stösst noch früh genug an ihre natürlichen Grenzen.
Damit haben wir grundsätzliches Monitoring der wichtigsten JVM-Metriken aktiviert und können die Anwendung problemlos in unseren Stack deployen, ohne dabei _blind_ zu sein.

=== Alerting

Natürlich wollen wir genauso wie wir für das Systemmonitoring _Alerting_ eingerichtet haben dasselbe auch für unsere Anwendungen machen.
Hierfür aktivieren wir einige Kapacitor-Tasks für den Time-Service.

Was aber wäre ein sinnvoller Alarm auf den wir reagieren müssten.

==== Speicherverbrauch

Sollte der Service ungewöhnlich viel Speicher verbrauchen möchten wir darüber benachrichtigt werden.

Wir haben die beiden Metriken _heap.used_ und _heap.max_. Hieraus lässt sich ganz einfach berechnen, wieviel Prozent des Heaps gerade in Verwendung sind. Genau wie zuvor auf Systemebene definieren wir nützliche Schwellwerte, bei deren Überschreitung ein Alarm an uns geschickt werden soll.

Das Tick-Script für diesen Use-Case berechnet zunächst aus _heap.used_ und _heap.max_ die Prozentuale Verwendung, generiert daraus über einen _Join_ eine neue Serie und verwendet diese, um Schwellwerte für Alarme zu definieren.

TIP: Diese Metrik gibt es natürlich auch schon _fertig_ über die Query  "SELECT mean("gauge") * 100  FROM "heap.usage" GROUP BY time(1m), "host" fill(null)"

Zunächst benötigen wir den Wert für Heap-Used.

[source, bash]
----
var used = stream |
   from().measurement('heap.used')
   | groupBy('host')
----

Zusätzlich müssen wir wissen, wieviel Heap insgesamt zur Verfügung steht.

[source, bash]
----
var total = stream |
   from().measurement('heap.max')
   | groupBy('host')
----

Wir können diese beiden Datensätze zusammen-joinen und daraus einen neuen Stream erzeugen, aus dem wir die Schwellwerte für den Alarm berechnen.

[source, bash]
----
used |
    join(total).
      as('used', 'total')
    | eval(lambda: "used.gauge" / "total.gauge")
       .as('used_percent').keep()
       | alert()
            .warn(lambda: "used_percent" > 0.8) <1>
            .crit(lambda: "used_percent" > 0.9) <2>
            .stateChangesOnly(1h) <3>
            .message('High Memory usage - {{ .Level}} - Percent Used: {{ index .Fields "used_percent"}}')
            .email()
             .to('<E-Mail adresse>')
----
<1> Warnungen wenn wir 80% Heap Auslastung haben
<2> Kritisch wenn wir 90% Heap Auslastung haben
<3> Report maximal einmal pro Stunde.

Wir laden das Skript in Kapacitor und aktivieren den Task.

[source, bash]vi
----
./kapacitor define billy_time_memory_alert -type stream -tick app_memory_alert.tick -dbrp "billy_time_metrics.autogen"
./kapacitor enable billy_time_memory_alert
----

Damit haben wir alles, was wir brauchen um den Service im nächsten Kapitel kontinuierlich zu bauen und zu deployen.

image::/assets/images/05_final_dashboard.png[Finales Dashboard, 800]

Das obige Dashboard zum importieren findet sich unter http://{{site.url}}/assets/dashboards/Billy-Time-dashboard-final.json.

Das Projekt zum klonen finden Sie unter https://github.com/dilgerma/billy-rpi-time.git.

[source, bash]
----
git clone https://github.com/dilgerma/billy-rpi-time.git
git checkout chapter-5
----



