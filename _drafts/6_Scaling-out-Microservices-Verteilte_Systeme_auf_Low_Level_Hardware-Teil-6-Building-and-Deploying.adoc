---
layout: default
title: Microservices auf Commodity Hardware Teil 6 - Building and Deploying
shortTitle: Microservices und Commodity Hardware Teil 6
documentationExpanded: false
comments: true
postsExpanded: true
categories: microservices spring-boot distributed-systems
published: true
excerpt: excerpt
root: ../../
---

= Scaling out Microservices - Verteilte Systeme auf einfachster Hardware - Teil 6 - Continuous Integration, Delivery, Deployment

Im letzten Kapitel haben wir die Grundlagen und Infrastruktur für einen ersten Service auf Basis von Spring-Boot geschaffen. In diesem Kapitel geht es nun darum, diesen Service zu bauen, automatisiert zu testen und anschließend in _Produktion_ zu bringen was zunächst einmal einfach heisst, der Service im Cluster zu deployen.

Wie immer gibt es hierfür unzählige Möglichkeiten und Toolchains - wir konzentrieren uns auf die gängigsten Tools und bauen daraus eine funktierende CI-Pipeline.

== Pipeline as Code

Zunächst brauchen wir den Build-Server der den _billy time_-Service baut.

Wir arbeiten hierfür mit Jenkins in der aktuellen Verstion 2.x. Die 2.x Linie unterstützt nativ die Idee von _Pipeline-as-Code_, also die Definition der Build-Pipeline im Source-Code.
Warum ist das so wichtig und interessant?

Eine typische Pipeline könnte für einen Service so abgebildet werden.

image::/assets/images/06_pipeline.png[Pipeline Steps, 800]

Jeder Schritt in der Pipeline basiert auf dem vorherigen.

Ein Build wird erst durch einen Commit angestossen. Der anschließende Testlauf wird erst gestartet, nachdem das Artefakt korrekt im ersten Pipeline-Schritt gebaut wurde. In Stage oder Produktion wird anschließend nur nach erfolgreichem Test deployt.

In den meisten Build-Tools ist üblich, die Schritte zum Bau eines Artefaktes in der Tool-eigenen DSL oder einfach in beispielsweise XML-Konfigurationen zu beschreiben. Man bricht also mit dem Paradigma, dass alles was zum Bau und Betrieb eines Services notwendig ist an einem Ort - nämlich dem Service-Repository - definiert ist.
Schlägt ein Build fehl oder kann ein Service nicht deployt werden muss die Ursache unter Umständen im Build-Server und dessen Konfiguration gesucht werden.

Ein beliebtes Problem ist beispielsweise, dass Artefakte aufgrund von fehlenden Berechtigungen nicht auf die Staging-Umgebung kopiert werden können.
Eine Anpassung in der Konfiguration ist schnell gemacht, für die Rechte des Kopierens wird _temporär_ einfach der _geheime_ und _niemandem_ bekannte Admin-User verwendet.
Einige Tage später kommt der Verantwortliche Entwickler aus dem Urlaub zurück und kocht vor Wut über diese offensichtlich dämliche Konfigurationsänderung.
Da die Konfiguration aber nicht historisiert ist und das täglich gezogene Backup schon seit Wochen unbemerkt nicht funktioniert ist es unmöglich, die alte Konfiguration einfach wieder herzustellen.
Es fehlt schlichtweg die Versionierung.

Die Konfiguration für den Build-Server, Deployment-Skripte ist nichts anderes als Code und genauso Bestandteil unseres Produktes wie der Source-Code in der Programmiersprache des Services. Und genauso wie der Sourcecode werden alle Artefakte und Bestandteile im Source-Repository verwaltet. Vor kurzem wurde die langerwartete Version 2.x des Jenkins-Build-Servers veröffentlicht.

== Jenkins 2.x

Mit Jenkins ist es mittlerweile sehr einfach, auch komplexe Pipelines in der eigenen Groovy-DSL zu definieren.
Wir werden den Jenkins wie einen Service in unserem Cluster deployen und wählen hierfür den Knoten mit der höchten Festplatten-Kapazizät.
Hierfür müssen wir nicht raten, denn wir haben diese Information im Grafana-Dashboard zur Hand.

image::/assets/images/05_disk_space_grafana.png[Grafana Disk Space]

Der Knoten _Pi48_ hat mit einigem Abstand die größte Kapazität und wird deshalb der primäre Build-Server-Knoten - der *master*.

Jenkins bietet kein offizielles Images für den Raspberry-PI, deswegen habe ich mir die Mühe gemacht, ein Image bereit zu stellen. Um einen Jenkins auf dem Pi48 zu starten loggen wir uns auf dem Knoten ein.

[source, bash]
----
docker volume create --name jenkins-data <1>
docker run -d -p 8080:8080 -p 50000:50000 -v jenkins-data:/var/jenkins_home dilgerm/rpi-jenkins:2.0.9 <2>
----
<1> Persistentes Volume für Jenkins erzeugen
<2> Jenkins startet auf Port 8080 und verwendet das soeben erzeugte Volume. Den Port 50000 brauchen wir später um Slave-Agents anzusprechen.

Der Jenkins ist schnell eingerichtet.

image::/assets/images/06_jenkins.png[Jenkins,800]

Die wichtigsten Plugins werden automatisch installiert.

image::/assets/images/06_jenkins_2.png[Jenkins,800]

Vergessen Sie zum Schluss nicht unter _Jenkins verwalten / Global Tool Configuration_ ein Git zu konfigurieren.
Da der Jenkins in einem Container läuft gibt es kein nativ installiertes Git und wir begnügen uns deshalb mit einer _JGit_-Installation die dem nativen Git in kaum etwas nachsteht.

image::/assets/images/06_jenkins_git_config.png[Jenkins,800]


=== Pipeline DSL

Mit Hilfe der Groovy-basierten Pipeline-DSL ist es sehr einfach, eine Pipeline _als Code_ zu definieren.
Hierfür legen wir im Projekt des _billy time_-Services ein _Jenkinsfile_ an und definieren 5 Stages für den Build des Services.

[source, bash]
----
node { <1>
    stage 'build' <2>
    stage 'integration-test' <3>
    stage 'docker-build' <4>
    stage 'docker-push' <5>
    stage 'deploy' <6>
}
----
<1> Ein Node definiert einen Knoten, auf dem das Projekt gebaut wird
<2> Zunächst bauen wir das Artefakt
<3> Ein Integration-Test stellt die Funktionalität übergreifend sicher (wie genau werden wir noch definieren)
<4> Zum Betrieb verwenden wir Docker - es wird also eine Stage zum Bauen eines Images geben
<5> Das Image werden wir in einer Registry bereitstellen
<6> Hat alles funktioniert wird der Service im Cluster deployt.

Sobald die Änderung im Repository gepusht ist definieren wir in der Jenkins-Oberfläche einen neuen Pipeline-Job.

image::/assets/images/06_pipeline_definition_01.png[Jenkins,800]

Die einzige wirklich wichtige Information, die Jenkins benötigt um die Pipeline initial anzulegen ist der Ort, wo das Pipeline-Skript abgelegt ist?

image::/assets/images/06_jenkins_pipeline_definition.png[Jenkins,800]

Starten wir die Pipeline legt Jenkins für uns die zuvor definierten Pipeline-Schritte und somit die Pipeline an. Natürlich passiert in keinem der Schritte bisher etwas sinnvolles, denn jeder der Schritte muss jetzt mit Leben gefüllt werden. Zunächst ist es wichtig, das Service-Artefakt zu bauen, denn das Artefakt dient als Grundlage für alle weiteren Pipeline-Schritte.

image::/assets/images/06_jenkins_pipeline.png[Jenkins,800]

Das Anlegen des Pipeline Jobs ist der einzige manuelle Schritt der über die Jenkins Oberfläche erfolgen muss. Alles weiter passiert direkt im Jenkinsfile und damit im Sourcecode.

=== Build Step

Den Build zu starten ist trivial.

[source, bash]
----
stage 'build'

    checkout scm <1>
    sh './gradlew build' <2>
----
<1> Checkout des Projekt-Repositories
<2> Mit 'sh' werden Shell-Skripte ausgeführt und wir starten so einfach den Build wie in einer Konsole.

Betrachten wir den Job in der Konsole sehen wir, dass der erste Schritt nun darin besteht, die konfigurierte Gradle-Version herunterzuladen.

TIP: Auf dem Jenkins selbst ist kein Gradle installiert - jeder Service und jeder Build definiert für sich selbst, welche Gradle-Version für den Build am besten geeignet ist.

image::/assets/images/06_jenkins_build.png[Jenkins,800]


Analog könnte jetzt die Integration-Test Phase implementiert werden, die beispielsweise nur Tests starten könnte die sehr lange dauern und die Grenzen der Anwendung testen, beispielsweise die Interaktion mit der Datenbank.

== Integration Test Build Step

Dieser Abschnitt ist absichtlich sehr kurz gehalten, da Integration Tests nicht im Fokus dieses Kapitels liegen, trotzdem gehen wir kurz darauf ein, damit die Pipeline hinterher vollständig implementiert ist.

Warum überhaupt brauchen wir eine Unterscheidung zwischen Integration- und Unit-Tests?
Lassen wir nicht idealerweise einfach immer beide mit laufen? Muss überhaupt zwischen den beiden Typen von Tests unterschieden werden?

Zunächst ist natürlich der Fokus ein anderer. Ein Unit-Test testet, wie der Name bereits suggeriert eine Einheit, ein in sich geschlossenes System.
Ein System kann beispielsweise eine Klasse oder eine Gruppe von Klassen sein, solange klar erkennbar ist, welche Funktionalität durch einem Unit-Test
sichergestellt werden soll.

Ein Integration-Test sprengt absichtlich genau dieses Unit-Grenze und testet eine Gruppe von Systemen und deren Interaktion.
Genau das macht Integration-Tests aber langsam, weil im Kontext eine Spring-Anwendung beispielsweise ein Spring-Context gestartet werden kann.
Das wichtigste Ziel von Unit-Tests muss es immer sein, schnell qualifiziertes Feedback an den Entwickler zu geben. Die Betonung liegt auf _schnell_, denn in allen Projekten erlebt man, dass langsame Tests die Entwickler ausbremsen und zwar so lange, bis die Tests lokal einfach nicht mehr ausgeführt werden.
Tests die nicht ausgeführt werden führen im besten Fall zu gelben Builds, im schlimmsten Fall zu Bugs in Produktion und dadurch enttäuschten Kunden und fehlenden Einnahmen.

Daher kanne es Sinn machen, den Tradeoff einzugehen, Integration-Tests nicht _immer_ für jeden lokalen Build auszuführen, sondern vielleicht nur auf dem Integration-Server.
Dann haben wir für die lokale Entwicklung schnelles Feedback und decken damit schon 80% der Fehlerquellen auf. Die restlichen 19% finden wir spätestens beim Build im CI-Server. Die Chance, dass ein Bug in System eingebaut wird ist dadurch also minimal.
Willkommen in der Welt der professionellen Softwareentwicklung.

Wie aber unterscheiden wir Unit- von Integration-Tests?
Hierfür gibt es mannigfaltige Möglichkeiten, die von Naming-Conventions (alle Integration-Tests enden auf *IntTest) bis zu Annotations (@IntegrationTest), Tags (JUnit5) oder Categories (JUnit4).

Für unseren Fall eignen sich Kategorien am besten, da JUnit 5 noch im Beta-Stadium ist und gerade der Support in den Entwicklungsumgebungen noch eher rudimentär.

=== JUnit Categories

JUnit bietet das Konzept der Kategorien mit dem Tests kategorisiert werden können. Aktuell unterstützen wir genau zwei Kategorien, Unit- und Integration-Tests. Weitere Kategorien könnten UI-Tests (Selenium, Protractor) oder Contract-Tests (Pact) sein.

Kategorien in JUnit basieren auf Klasen, die als Identifier für die jeweiligen Kategorien dienen.
Wir definieren im *package* _de.effectivetrainings.test.support_ das Interface _IntegrationTest_.

[source,bash]
----
package de.effectivetrainings.test.support;

/**
 * Marks a Test as Integration Test.
 */
public interface IntegrationTest {
}
----

Im *package* _de.effectivetrainings_ definieren wir außerdem den Test _BillyTimeApplicationTest_.

[source, bash]
----
@RunWith(SpringJUnit4ClassRunner.class)
@SpringBootTest(classes = BillyTimeApplication.class, webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT) <1>
@ActiveProfiles("unit-test-env") <2>
@Category(de.effectivetrainings.test.support.IntegrationTest.class) <3>
public class BillyTimeApplicationTests {

    @Autowired
    private TimeTrackingResource timeTrackingResource;
    @Value("${local.server.port}") <4>
    private String serverPort;

    @Test
    public void startApplicationAndVerify() {
        RestTemplate restTemplate = new TestRestTemplate();
        final ResponseEntity<List> result = restTemplate.getForEntity(serviceUri(), List.class); <5>
        assertFalse(result
                .getBody()
                .isEmpty());
    }

    private URI serviceUri() { <6>
        return UriComponentsBuilder
                .newInstance()
                .scheme("http")
                .host("localhost")
                .port(serverPort)
                .path(TimeTrackingResource.PROJECTS_URI)
                .build()
                .toUri();
    }
}
----
<1> Mit der Annotation @SpringBootTest initialisieren wir den Test so, dass ein echter Container gestartet wird, gegen den wir testen können. footnote:[http://docs.spring.io/spring/docs/current/spring-framework-reference/html/integration-testing.html[Spring Boot Integration Test Support]]
<2> Das Profil "unit-test-env" für Integration Testing. Das Profil hat aktuell keine Bedeutung.
<3> Kategorisierung des Tests
<4> Port der gestarteten Embedded-Jetty Instanz.
<5> HTTP-Request gegen die Anwendung
<6> Service-URI auf die TimeTrackingResource

Spring bietet einen ausgezeichneten Support für Integration-Tests mit Embedded-Containern. Das weiß jeder umso mehr zu schätzen, der bereits in Projekten gearbeitet hat, in denen das alles von Hand zu machen war.
Allein indem der Test mit @SpringBootTest annotiert wird kümmert sich Spring um das ganze Scaffolding und fährt die Anwendung in einem Embedded-Jetty Container hoch (Tomcat geht natürlich auch).

Wir annotieren den Test mit _@Category(de.effectivetrainings.test.support.IntegrationTest.class)_. Nur Integration-Tests werden annotiert, alle anderen Tests gelten als normale Unit Tests.

TIP: Ich erlebe es immer wieder in Projekten, dass das falsch gemacht wird. Integration-Tests werden als _Integration-Test_ annotiert oder markiert, Unit Tests als Unit-Tests. Oft wird dann übersehen, dass nicht annotierte Tests gar nicht laufen, was dazu verleitet sich in falscher Sicherheit zu wiegen, weil das Feedback ausbleibt.

Zuletzt sorgen wir in der _build.gradle_ dafür, dass Gradle auch von der Kategorisierung weiß und Integration Tests beim normalen _Build_ ignoriert.

[source, bash]
----
test {
  useJUnit {
    excludeCategories 'de.effectivetrainings.test.support.IntegrationTest'
  }
}
----

Wir definieren zusätzlich den Task Integration-Test, der nichts anderes tut als Integration-Tests auszuführen.

[source, bash]
----
task integrationTest(type: Test) {
    useJUnit {
        includeCategories 'de.effectivetrainings.test.support.IntegrationTest'
    }
}
----

Jetzt kann der normale Build ganz einfach über _gradle build_ gestartet werden. Die Integration-Tests sind ausführbar über _gradle integrationTest_.

Nach dieser Vorarbeit ist es ganz einfach, die Integration-Test-Phase im _Jenkinsfile_ zu definieren.

[source, bash]
----
node {
    stage 'build'

    checkout scm
    sh './gradlew build'

    stage 'integration-test'

    sh 'gradlew integrationTest' <1>

    stage 'docker-build'
    stage 'docker-push'
    stage 'deploy'
}
----
<1> Integration Tests Phase

== Docker Build Step

Docker ist ein fundamentaler Baustein der CI-Pipeline. Artefakte werden nicht mehr als War- oder Jar- oder EAR deployt sondern als Container.
Jeder Build erzeugt ein Docker-Image und damit einen potentiellen Release-Kandidaten. Das Image kann (muss aber nicht) jetzt auf die verschiedenen Staging-Umgebungen deployt und getestet werden.

Genauso gut kann das Image aber lokal bei einem Entwickler gestartet werden um damit auffälliges Verhalten in Produktion nachzustellen.
Der Vorteil - die Konfiguration der Umgebung zumindest für die Anwendung selbst entspricht genau der Konfiguration wie in Produktion da alles was nötig ist um die Anwendung zu betreiben bereits in das Image gebacken wurde.

Es gibt grundsätzlich immer zwei Möglichkeiten, diese Pipeline-Phase zu implementieren.

Entweder man verlässt sich auf eines der unzähligen https://plugins.gradle.org/search?term=docker[Docker-Gradle-Plugins] und integriert Docker in den Build-Prozess oder man definiert alles für den Docker-Build notwendige in einem eigenen Dockerfile und behält so die volle Kontrolle.
Wir verwenden hierfür einen hybriden Ansatz - das Dockerfile wird über Gradle definiert. Alles weitere überlassen wir dann dem CI-Server.

Das wahrscheinlich am häufigsten verwendete Plugin ist das von https://github.com/bmuschko/gradle-docker-plugin[Benjamin Muschko].

=== Gradle Integration

Die komplette Konfiguration für den Docker-Build ist überschaubar. Zunächst definieren wir den Task, der das Dockerfile aus der Projektkonfiguration generiert.

[source, bash]
----
task prepareDockerBuild(type: Dockerfile) {
    dependsOn copyJar <1>
    destFile = project.file('build/docker/Dockerfile') <2>
    from 'dilgerm/rpi-app-base' <3>
    maintainer 'Martin Dilger <martin@effectivetrainings.de>'
    addFile "${serviceName}.jar", "/app/${serviceName}.jar" <4>
    entryPoint "java","-Djava.security.egd=file:/dev/./urandom","-jar","/app/${serviceName}.jar" <5>
}
----
<1> Prepare beinhaltet auch, die Artefakte zu kopieren
<2> Dockerfile im Build-Verzeichnis 'build/docker'
<3> Ein mögliches Base-Image für ein Deployment auf der ARM-Plattform
<4> Wir fügen nichts weiter als das soeben gebaute Jar-File in das Image.
<5> Start der Anwendung ist nur der Befehl _java -jar ..._

Für den Build eines Docker-Images wird ein _Dockerfile_ benötigt. Wir haben uns entschieden, das File nicht selbst zu schreiben sondern es durch Gradle generieren zu lassen.
Der Docker-Build wird nicht im Root-Verzeichnis ausgeführt sondern im Unterverzeichnis _build/docker_. Beim Docker-Build werden alle Dateien und Verzeichnisse im Build-Verzeichnis als Build-Context an den Docker-Daemon gesendet, daher begrenzen wir den Context und die zu übertragenden Daten auf ein Minimum und kopieren alle zum Build notwendigen Dateien explizit in das Build-Verzeichnis.

Üblicherweise wäre es sinnvoll, auch den kompletten Docker-Build Schritt im Build-File umgebungsunabhängig zu definieren. Ein schönes Beispiel für diese Art der Konfiguration findet sich beispielsweise http://container-solutions.com/how-to-build-docker-images-with-gradle/[hier].

Die Konfiguration für den Docker-Aufruf aus Gradle wäre in diesem Task definiert.

[source, bash]
----
task docker(type: DockerBuildImage) {
    dependsOn createDockerfile
    dependsOn copyJar
    if (System.env.DOCKER_HOST) {
        url = "$System.env.DOCKER_HOST".replace("tcp", "https")
        if (System.env.DOCKER_CERT_PATH) {
            certPath = new File(System.env.DOCKER_CERT_PATH)

        }
    } else {
        url = 'unix:///var/run/docker.sock'
    }
    inputDir = createDockerfile.destFile.parentFile
    tag = "dilgerm/$serviceName:$project.version" <1>
}
----
<1> Das Image wird gebaut und mit dilgerm/billy-time:0.0.1-SNAPSHOT getaggt. Das ändert sich später noch.

Leider ist vom Gradle Docker Plugin verwendete API (Docker-Java) alles andere als stabil und funktioniert derzeit überhaupt nicht, da der Zugriff auf Unix-Sockets aus Java nicht möglich zu sein scheint.

CAUTION: Eines von vielen Problemen geht beispielsweise aus diesem https://github.com/docker-java/docker-java/issues/537[Bug] hervor.

Wir verzichten also auf den letzten Schritt des Docker-Aufrufs aus Gradle und gehen die letzten Meter _im Jenkinsfile_ über das https://go.cloudbees.com/docs/cloudbees-documentation/cje-user-guide/chapter-docker-workflow.html[Docker Pipeline Plugin].

[source, bash]
----
stage 'docker-build'
    //tasks
    sh './gradlew prepareDockerBuild'
    def img = docker.build("dilgerm/billy-time:${env.BUILD_ID}", 'build/docker'); <1>
----
<1> Docker-Build über Docker-Pipeline, _build/docker_ ist das Verzeichnis, in dem Gradle das Dockerfile abgelegt hat.

Das Docker Pipeline Plugin ist eine einfache und komfortable Möglichkeit, Docker aus einem Pipeline-Script heraus zu steuern.
Ein wirklich schönes Beispiel findet sich beispielsweise in diesem https://github.com/jenkinsci/docker-workflow-plugin/blob/master/demo/repo/flow.groovy[Github-Skript].

== Docker Push Step

Da wir den Service auf beliebigen Knoten im Cluster verteilen und provisionieren möchten müssen wir das gerade gebaute Docker-Image auch verteilen können. Eine Möglichkeit hierzu ist einfach die Dockerregistry im _Dockerhub_.

TIP: Möchten Sie das auch machen legen Sie sich bitte einen eigenen Dockerhub-Account an.

Wir bauen also das Image und pushen es anschließend zu Dockerhub.
Damit der Push aus dem Jenkins-Knoten funktioniert müssen wir die Dockerhub-Credentials irgendwo hinterlegen.
Die Credentials jedoch im Jenkinsfile und somit in der Versionskontrolle zu hinterlegen wäre naiv, besser ist die Konfiguration direkt im Jenkins.

=== Jenkins Credentials Plugin

Auch für die sichere Verwaltung der Credentials bietet Jenkins eine Lösung mit dem https://wiki.jenkins-ci.org/display/JENKINS/Credentials+Plugin[Credentials Plugin]. Das Credentials-Plugin befreit uns von der Versuchung, Credentials im Jenkinsfile und damit für alle sichtbar zu hinterlegen. Stattdessen werden die Credentials zentral im Jenkins verwaltet und nur noch über IDs referenziert. Die einzelnen Plugins bekommen die Credentials also gar nicht zu sehen, sondern wissen nur, _welche_ Credentials zu verwenden sind.

Viele Plugins bieten die Möglichkeit, mit Credential-Ids statt echten Credentials zu arbeiten.

Das Credentials Plugin verwaltet Credentials hierarchisch unterteilt in _Stores_ und _Domänen_.
Als Standardspeicher-Art für Credentials verwendet Jenkins den System-Store. Die Standard-Domäne ist _global_, verwaltet also Credentials
die überall und in allen Jobs verwendet werden können.

Um neue Credentials für Dockerhub zu hinterlegen öffnen Sie zunächst die Zugangsdaten von der Startseite aus.

image::/assets/images/06_credentials_01.png[Credentials, 350]

Anschließend konfigurieren wir die Credentials für die _global_-Domäne.

image::/assets/images/06_credentials_02.png[Credentials, 800]

Anschließend können wir ganz einfach neue Credentials hinterlegen, für unseren Fall eignet typischerweise einfach _Benutzername & Passwort_.

image::/assets/images/06_credentials_03.png[Credentials, 800]

TODO Credentials Binding Plugin

Sobald die Credentials hinterlegt sind ist der Schritt für den Push in die Registry ganz einfach.

[source, bash]
----
stage 'push'
    docker.withRegistry('https://index.docker.io/v1/', 'dockerhub') { <1>
        img.push();
    }
----
<1> Für die Registry kann sowohl URL als auch optional die Credentials-ID hinterlegt werden.

Die Credentials für Dockerhub sind im Credentials-Plugin unter der ID 'dockerhub' hinterlegt.

== Docker (simple) Deploy Step

Wir wollen neue Versionen so schnell wie möglich und so nahe wie möglich an Produktion bringen. Zunächst wäre es schön, neue Versionen des Services irgendwo zu deployen. _Irgendwo_ ist in diesem Fall relativ klar definiert, denn aktuell haben wir nichts weiter als den Docker-Host auf dem auch der Jenkins deployt ist. Wir werden im nächsten Kapitel ausführlich über Deployment und Orchestrierung von Services sprechen, für jetzt aber möchten wir nur zeigen, dass wir fähig sind, Services kontinuierlich zu deployen.

Wir lassen den Jenkins einfach nach jedem erfolgreichen Build eine neue Version deployen. Aktuell müssen wir uns noch selbst darum kümmern, veraltete Versionen wieder zu entfernen, sonst gibt der Raspberry relativ schnell auf.

[source, bash]
----
 stage 'deploy'
    img.run('-p 8080') <1>
----
<1> Deployt den Service und mappt einen beliebigen Host-Post auf den Container-Port 8080

== Build Metriken

Zu Beginn haben wir definiert, dass alles was wir anpassen, ändern, verbessern sich auch in den Metriken der Anwendung widerspiegeln muss. Das gilt nicht nur für die Software sonden ganz speziell auch für den kompletten Lebenszyklus der Anwendung - und ganz speziell für den Build.
Metriken über den Build sagen sehr viel über die Entwicklung einer Anwendung aus.

Dinge, die hierbei grundsätzlich (aber nicht exklusiv) interessant sind sind beispielsweise:
- Build Dauer
- Erfolg / Misserfolg Quote
- Anzahl fehlgeschlagener Tests
- Anzahl Tests (sollte beispielsweise nicht sinken..)
- Build-Artefakt-Größe

Natürlich verwenden wir hierfür denselben Stack wie auch für das Monitoring der Anwendung selbst - InfluxDB / Grafana. Jeder Build sollte die neu gewonnenen Erkenntnisse in der InfluxDB speichern und natürlich auch visualisieren, damit wir beispielsweise sofort bei einer signifikaten Verschlechterung der Build-Zeit reagieren können.
Das lässt sich anschließend auch wunderbar mit einem Alert in _Kapacitor_ verknüpfen.

Das Rad müssen wir hierfür allerdings nicht neu erfinden, denn es gibt bereits das https://github.com/jenkinsci/influxdb-plugin[Jenkins Influx DB Plugin]. Zum jetzigen Zeitpunkt ist das Plugin sehr rudimentär und liefert nur die allerwichtigsten Metriken, besser als nichts ist es aber allemal.

Sobald das Plugin installiert ist ist es möglich, die Verbindung zur InfluxDB in der Jenkins-Konfiguration zu hinterlegen.

image::/assets/images/06_jenkins_metrics.png[Metrics, 800]

TIP: Aktuell bietet das Plugin weder die Möglichkeit, das Credentials-Plugin zu verwenden noch erlaubt es, die Retention Policy in der die Daten abgelegt werden zu konfigurieren. Die Credentials müssen also Plain hinterlegt werden.

Das Plugin selbst ist bereits Pipeline-kompatibel, kann also aus dem Jenkinsfile heraus angesprochen werden.
Für Freestyle-Jobs werden die Daten in die Influx als _Post-Build-Step_ übertragen. Meines Wissens nach ist das aktuell über eine Pipeline nicht möglich, da im Jenkinsfile selbst keine Post-Build-Steps konfiguriert werden können.
Die Daten die aus der Pipeline heraus übertragen werden sind also teilweise unvollständig - beispielsweise kann kein richtiger Build-Status übertragen werden, da der Build zu diesem Zeitpunkt noch läuft und Jenkins nicht sagen kann, ob der Build erfolgreich war oder nicht.

Um die Daten als letzten Step in die Influx zu übertragen definieren wir einen neuen Pipeline Step.

[source, bash]
----
stage 'report'
    step(['$class' : 'InfluxDbPublisher', 'selectedTarget' : 'influx']) <1>
----
<1> _selectedTarget_ bezieht sich auf die Influx-Konfiguration

Mehr ist nicht zu konfigurieren. Die wichtigste Metrik (Build Dauer) bekommen wir hiermit schon und können diese über Grafana visualisieren.

image::/assets/images/06_jenkins_build_duration.png[Build Dauer, 800]

Die Datenbank 'build_metrics', in die die Metriken gespeichert werden haben wir in der Jenkins-Konfiguration festgelegt.

image::/assets/images/06_jenkins_metrics_02.png[Metriken, 800]

Für jeden Job wird dort eine eigenes Measurement angelegt mit dem Namen "build_<job-name>".

Die Query zum Laden der Build-Zeiten in Grafana ist einfach und wird am besten über den Editor konfiguriert. Jenkins speichert die Build-Zeiten in Millisekunden.

[source, bash]
----
SELECT last("jobduration") FROM "build_billy_time" WHERE $timeFilter GROUP BY time($interval) fill(null)
----

Um sich die Build-Zeiten in den Influx in einer Minutenauflösung zu betrachen reicht folgende Query.

[source, bash]
----
select (jobduration / 1000 / 60) as build_min from build_billy_time
----

image::/assets/images/06_build_mins.png[Metriken, 800]

Eine Build-Zeit von 5 Minuten inklusive Deployment scheint zunächst akzeptabel.
Die beste Metrik aber hilft uns nichts, wenn wir sie nicht kontinuierlich auswerten.

An den obigen Daten sieht man bereits, dass die Varianz der Build-Zeiten sehr hoch ist und zwischen 4,8 und 5,8 Minuten schwankt.
Was also wäre ein sinnvoller Alert, auf den wir reagieren müssten?

Man könnte sich beispielsweise vorstellen, den Mittelwert der letzten 10 Builds als Grad für die durchschnittliche (Soll)-Build-Dauer zu verwenden und zumindest einen Alert zu schicken, wenn ein Build um mehr als 20% von diesem Soll-Wert abweicht.

TODO Skript schreiben?? Gar nicht so einfach..

== Fazit

Wir haben eine komplette Build-Pipeline aus dem Nichts heraus aufgebaut und können jetzt den Time-Service für jeden Commit bauen, testen, verteilen und deployen. Außerdem haben wir auch die wichtigste Metrik, die Build-Dauer aktiviert.
Natürlich ist die Pipeline noch alles andere als ideal - so wird der Service zwar deployt aber immer auf den gleichen Knoten auf dem jetzt mehr oder weniger zufällig der Build läuft.

Die Arbeit mit den Pipeline-Skripten ist wirklich einfach und auch in der Praxis so problemlos verwendbar.
Natürlich gibt es noch die eine oder andere Stolperfalle, wie beispielsweise die fehlende Möglichkeit, _Post-Build_-Schritte zu definieren.
Für den Moment aber können wir mit dem Erreichten zufrieden sein.

Im nächsten Kapitel kümmern wir uns um die Orchestrierung und Deployment unserer Service-Landschaft und nutzen hierfür die Tools _at Hand_- Docker und Docker-Compose.
Mit Docker 1.12 ist die Orchestrierung von Containern wirklich einfach geworden und Tools wie https://www.weave.works/[Weave] verlieren ein bisschen an Relevanz, zumindest für einfache Projekte.

Hierfür werden wir auch weitere Container benötigen wie beispielsweise eine relationale Datenbank, um Daten zu persistieren. Allein dadurch wird sich eine ganze Menge neuer Probleme auftun, die es noch zu lösen gilt.